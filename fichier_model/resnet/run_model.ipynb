{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmo\\AppData\\Local\\Temp\\ipykernel_74544\\1815524006.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)\n",
    "train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n",
    "train = shuffle(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=225000), Label(value='0 / 225000')…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "013a5c66208f492db9898be4ba188c6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_timestamp(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):#parallel_apply\n",
    "        return 0.0\n",
    "    else:\n",
    "        try:\n",
    "            return float(pd.Timestamp(x).value / 10**18)\n",
    "        except:\n",
    "            return 0\n",
    "train[['read_at','date_added','date_updated' ,'started_at']] = train[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "inputs_data = train[['review_text','n_comments', 'n_votes','read_at','date_added','date_updated','started_at']]\n",
    "outputs_data = keras.utils.to_categorical(train['rating'], num_classes=6)\n",
    "train_in, validation_in, train_out, validation_out = train_test_split(inputs_data, outputs_data, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_in = [train_in['review_text'], train_in['n_comments'], train_in['n_votes'], train_in['read_at'], train_in['date_added'], train_in['date_updated'], train_in['started_at']]\n",
    "validation_in = [validation_in['review_text'], validation_in['n_comments'], validation_in['n_votes'], validation_in['read_at'], validation_in['date_added'], validation_in['date_updated'], validation_in['started_at']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11250/11250 [==============================] - 692s 60ms/step - loss: 1.5335 - categorical_accuracy: 0.3390 - f1_score: 0.2909 - val_loss: 1.4365 - val_categorical_accuracy: 0.4086 - val_f1_score: 0.3530\n",
      "Epoch 2/10\n",
      "11250/11250 [==============================] - 668s 59ms/step - loss: 1.2319 - categorical_accuracy: 0.4749 - f1_score: 0.4538 - val_loss: 1.1213 - val_categorical_accuracy: 0.5153 - val_f1_score: 0.4972\n",
      "Epoch 3/10\n",
      "11250/11250 [==============================] - 658s 58ms/step - loss: 1.0732 - categorical_accuracy: 0.5397 - f1_score: 0.5323 - val_loss: 1.0750 - val_categorical_accuracy: 0.5520 - val_f1_score: 0.5437\n",
      "Epoch 4/10\n",
      "11250/11250 [==============================] - 670s 60ms/step - loss: 1.0198 - categorical_accuracy: 0.5642 - f1_score: 0.5589 - val_loss: 1.0338 - val_categorical_accuracy: 0.5600 - val_f1_score: 0.5509\n",
      "Epoch 5/10\n",
      "11250/11250 [==============================] - 673s 60ms/step - loss: 0.9868 - categorical_accuracy: 0.5790 - f1_score: 0.5746 - val_loss: 1.0083 - val_categorical_accuracy: 0.5683 - val_f1_score: 0.5626\n",
      "Epoch 6/10\n",
      "11250/11250 [==============================] - 693s 62ms/step - loss: 0.9623 - categorical_accuracy: 0.5896 - f1_score: 0.5860 - val_loss: 0.9881 - val_categorical_accuracy: 0.5767 - val_f1_score: 0.5730\n",
      "Epoch 7/10\n",
      "11250/11250 [==============================] - 703s 62ms/step - loss: 0.9391 - categorical_accuracy: 0.5995 - f1_score: 0.5964 - val_loss: 1.0120 - val_categorical_accuracy: 0.5730 - val_f1_score: 0.5665\n",
      "Epoch 8/10\n",
      "11250/11250 [==============================] - 705s 63ms/step - loss: 0.9195 - categorical_accuracy: 0.6085 - f1_score: 0.6059 - val_loss: 0.9930 - val_categorical_accuracy: 0.5790 - val_f1_score: 0.5761\n",
      "Epoch 9/10\n",
      "11250/11250 [==============================] - 725s 64ms/step - loss: 0.8998 - categorical_accuracy: 0.6180 - f1_score: 0.6157 - val_loss: 0.9822 - val_categorical_accuracy: 0.5809 - val_f1_score: 0.5780\n",
      "Epoch 10/10\n",
      "11250/11250 [==============================] - 730s 65ms/step - loss: 0.8810 - categorical_accuracy: 0.6260 - f1_score: 0.6239 - val_loss: 0.9907 - val_categorical_accuracy: 0.5801 - val_f1_score: 0.5764\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2529e1d9690>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.22)\n",
    "sheduler = keras.callbacks.LearningRateScheduler(scheduler,0)\n",
    "\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    model = resnet1.ResNet50(vocabulary)\n",
    "    chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/resnet1/', save_weights_only=True,\n",
    "        monitor='val_f1_score',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "    if not os.path.exists(f\"logs/{model.name}\"):\n",
    "            os.mkdir(f\"logs/{model.name}\")\n",
    "    if not os.path.exists(f\"checkpoint/{model.name}\"):\n",
    "        os.mkdir(f\"checkpoint/{model.name}\")\n",
    "    model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.0001),\n",
    "                               loss=keras.losses.categorical_crossentropy,\n",
    "                               metrics=[keras.metrics.categorical_accuracy,\n",
    "                                        tfa.metrics.F1Score(num_classes=6, average='weighted')\n",
    "                                        ])\n",
    "\n",
    "    model.fit(train_in, train_out, validation_data=(validation_in, validation_out), epochs=10, batch_size=64, callbacks=[chekpoint, sheduler])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 157s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 39s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "val_res = model.predict(validation_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "val_out = np.argmax(validation_out, axis=1)\n",
    "train_out = np.argmax(train_out, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=119512), Label(value='0 / 119512')…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cae4ad82531447f2b48ab77902e6f0d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14939/14939 [==============================] - 109s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test[['read_at','date_added','date_updated' ,'started_at']] = test[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)\n",
    "\n",
    "test_data = [test['review_text'], test['n_comments'], test['n_votes'], test['read_at'], test['date_added'], test['date_updated'], test['started_at']]\n",
    "restest = model.model.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/180000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697c040a9afc43a487e37d559e40b083"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/478033 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "933796d0a7f849669ed172bdfff976b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/720000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a45c78a6abe4429b429b52aaf62e85b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff = []\n",
    "for line in tqdm(val_res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "val_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "test_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "train_data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.44      0.55     24800\n",
      "           1       0.55      0.34      0.42     22993\n",
      "           2       0.55      0.52      0.53     58041\n",
      "           3       0.64      0.65      0.64    151064\n",
      "           4       0.63      0.72      0.67    250900\n",
      "           5       0.76      0.70      0.73    212202\n",
      "\n",
      "    accuracy                           0.66    720000\n",
      "   macro avg       0.64      0.56      0.59    720000\n",
      "weighted avg       0.66      0.66      0.66    720000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_out, train_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.40      0.49      6188\n",
      "           1       0.51      0.31      0.38      5725\n",
      "           2       0.50      0.47      0.48     14586\n",
      "           3       0.58      0.59      0.58     37908\n",
      "           4       0.58      0.68      0.63     62788\n",
      "           5       0.72      0.66      0.69     52805\n",
      "\n",
      "    accuracy                           0.61    180000\n",
      "   macro avg       0.59      0.51      0.54    180000\n",
      "weighted avg       0.62      0.61      0.61    180000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_out, val_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "test['rating'] = test_data\n",
    "\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])\n",
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df.to_csv('submission_unet5_embedding_class_weights_model.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.model.save('unet5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
