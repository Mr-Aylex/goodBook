{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmo\\AppData\\Local\\Temp\\ipykernel_22960\\1815524006.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)\n",
    "train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n",
    "train = shuffle(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=225000), Label(value='0 / 225000')â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9e97dfd124c429fab546b871a61aa7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_timestamp(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x): # parallel_apply\n",
    "        return 0.0\n",
    "    else:\n",
    "        try:\n",
    "            return float(pd.Timestamp(x).value / 10**18)\n",
    "        except:\n",
    "            return 0\n",
    "train[['read_at','date_added','date_updated' ,'started_at']] = train[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "inputs_data = train[['review_text','n_comments', 'n_votes','read_at','date_added','date_updated','started_at']]\n",
    "outputs_data = keras.utils.to_categorical(train['rating'], num_classes=6)\n",
    "train_in, validation_in, train_out, validation_out = train_test_split(inputs_data, outputs_data, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_in = [train_in['review_text'], train_in['n_comments'], train_in['n_votes'], train_in['read_at'], train_in['date_added'], train_in['date_updated'], train_in['started_at']]\n",
    "validation_in = [validation_in['review_text'], validation_in['n_comments'], validation_in['n_votes'], validation_in['read_at'], validation_in['date_added'], validation_in['date_updated'], validation_in['started_at']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transf5\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 300)         0           ['input_1[0][0]']                \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " token_and_position_embedding (  (None, 300, 300)    32939700    ['text_vectorization[0][0]']     \n",
      " TokenAndPositionEmbedding)                                                                       \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 300, 300)    663200      ['token_and_position_embedding[0]\n",
      " erEncoder)                                                      [0]']                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 5, 300)      0           ['transformer_encoder[0][0]']    \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 4)            0           ['input_4[0][0]',                \n",
      "                                                                  'input_5[0][0]',                \n",
      "                                                                  'input_6[0][0]',                \n",
      "                                                                  'input_7[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1500)         0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 32)           160         ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1532)         0           ['flatten[0][0]',                \n",
      "                                                                  'dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           98112       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 34)           0           ['dropout_1[0][0]',              \n",
      "                                                                  'input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 16)           560         ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16)           0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           272         ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 6)            102         ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,704,186\n",
      "Trainable params: 33,704,186\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/6\n",
      "5625/5625 [==============================] - 327s 58ms/step - loss: 1.3473 - categorical_accuracy: 0.4259 - f1_score: 0.4008 - val_loss: 1.1059 - val_categorical_accuracy: 0.5277 - val_f1_score: 0.5118 - lr: 0.0010\n",
      "Epoch 2/6\n",
      "5625/5625 [==============================] - 356s 63ms/step - loss: 1.1328 - categorical_accuracy: 0.5149 - f1_score: 0.5067 - val_loss: 1.0671 - val_categorical_accuracy: 0.5364 - val_f1_score: 0.5323 - lr: 1.5000e-04\n",
      "Epoch 3/6\n",
      "3155/5625 [===============>..............] - ETA: 3:13 - loss: 1.1151 - categorical_accuracy: 0.5231 - f1_score: 0.5160"
     ]
    }
   ],
   "source": [
    "model_list = [transf5]\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.15\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    for model_obj in model_list:\n",
    "        model = model_obj.Model(vocabulary)\n",
    "        model.model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "                           loss=keras.losses.categorical_crossentropy,\n",
    "                           metrics=[keras.metrics.categorical_accuracy, tfa.metrics.F1Score(num_classes=6, average='weighted')]\n",
    "                           )\n",
    "        print(model.name)\n",
    "        print(model.model.summary())\n",
    "        if not os.path.exists(f\"logs/{model.name}\"):\n",
    "            os.mkdir(f\"logs/{model.name}\")\n",
    "        chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/{model.name}.h5',\n",
    "        monitor='val_f1_score',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "        sheduler = keras.callbacks.LearningRateScheduler(scheduler,0)\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}\")\n",
    "        model.run_experiment(train_in, train_out, validation_in, validation_out, epochs=6, callbacks=[sheduler,chekpoint, tensorboard_callback], batch_size=128)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.save('transf5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
