{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)\n",
    "#train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n",
    "train = shuffle(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=225000), Label(value='0 / 225000')â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8530f05de9ce4b799dbed0a729ac72f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_timestamp(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):#parallel_apply\n",
    "        return 0.0\n",
    "    else:\n",
    "        try:\n",
    "            return float(pd.Timestamp(x).value / 10**18)\n",
    "        except:\n",
    "            return 0\n",
    "train[['read_at','date_added','date_updated' ,'started_at']] = train[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "inputs_data = train[['review_text','n_comments', 'n_votes','read_at','date_added','date_updated','started_at']]\n",
    "outputs_data = keras.utils.to_categorical(train['rating'], num_classes=6)\n",
    "train_in, validation_in, train_out, validation_out = train_test_split(inputs_data, outputs_data, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_in = [train_in['review_text'], train_in['n_comments'], train_in['n_votes'], train_in['read_at'], train_in['date_added'], train_in['date_updated'], train_in['started_at']]\n",
    "validation_in = [validation_in['review_text'], validation_in['n_comments'], validation_in['n_votes'], validation_in['read_at'], validation_in['date_added'], validation_in['date_updated'], validation_in['started_at']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn1\n",
      "Epoch 1/8\n",
      "5625/5625 [==============================] - 86s 15ms/step - loss: 1.4799 - categorical_accuracy: 0.3531 - f1_score: 0.2513 - val_loss: 1.4787 - val_categorical_accuracy: 0.3519 - val_f1_score: 0.2659 - lr: 0.0100\n",
      "Epoch 2/8\n",
      "5625/5625 [==============================] - 83s 15ms/step - loss: 1.4782 - categorical_accuracy: 0.3542 - f1_score: 0.2517 - val_loss: 1.4768 - val_categorical_accuracy: 0.3553 - val_f1_score: 0.2508 - lr: 0.0082\n",
      "Epoch 3/8\n",
      "5625/5625 [==============================] - 91s 16ms/step - loss: 1.4778 - categorical_accuracy: 0.3546 - f1_score: 0.2519 - val_loss: 1.4766 - val_categorical_accuracy: 0.3538 - val_f1_score: 0.2599 - lr: 0.0067\n",
      "Epoch 4/8\n",
      "5625/5625 [==============================] - 88s 16ms/step - loss: 1.4775 - categorical_accuracy: 0.3544 - f1_score: 0.2510 - val_loss: 1.4764 - val_categorical_accuracy: 0.3553 - val_f1_score: 0.2442 - lr: 0.0055\n",
      "Epoch 5/8\n",
      "5625/5625 [==============================] - 83s 15ms/step - loss: 1.4772 - categorical_accuracy: 0.3549 - f1_score: 0.2511 - val_loss: 1.4768 - val_categorical_accuracy: 0.3545 - val_f1_score: 0.2385 - lr: 0.0045\n",
      "Epoch 6/8\n",
      "5625/5625 [==============================] - 89s 16ms/step - loss: 1.4771 - categorical_accuracy: 0.3545 - f1_score: 0.2507 - val_loss: 1.4762 - val_categorical_accuracy: 0.3541 - val_f1_score: 0.2576 - lr: 0.0037\n",
      "Epoch 7/8\n",
      "5625/5625 [==============================] - 82s 15ms/step - loss: 1.4769 - categorical_accuracy: 0.3549 - f1_score: 0.2502 - val_loss: 1.4769 - val_categorical_accuracy: 0.3554 - val_f1_score: 0.2469 - lr: 0.0030\n",
      "Epoch 8/8\n",
      "5625/5625 [==============================] - 82s 15ms/step - loss: 1.4767 - categorical_accuracy: 0.3546 - f1_score: 0.2494 - val_loss: 1.4758 - val_categorical_accuracy: 0.3552 - val_f1_score: 0.2462 - lr: 0.0025\n",
      "cnn2\n",
      "Epoch 1/8\n",
      "5625/5625 [==============================] - 86s 15ms/step - loss: 1.1109 - categorical_accuracy: 0.5228 - f1_score: 0.5156 - val_loss: 0.9860 - val_categorical_accuracy: 0.5781 - val_f1_score: 0.5743 - lr: 0.0100\n",
      "Epoch 2/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.9583 - categorical_accuracy: 0.5899 - f1_score: 0.5874 - val_loss: 0.9633 - val_categorical_accuracy: 0.5869 - val_f1_score: 0.5821 - lr: 0.0082\n",
      "Epoch 3/8\n",
      "5625/5625 [==============================] - 85s 15ms/step - loss: 0.9065 - categorical_accuracy: 0.6140 - f1_score: 0.6122 - val_loss: 0.9632 - val_categorical_accuracy: 0.5883 - val_f1_score: 0.5797 - lr: 0.0067\n",
      "Epoch 4/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.8611 - categorical_accuracy: 0.6358 - f1_score: 0.6344 - val_loss: 0.9575 - val_categorical_accuracy: 0.5963 - val_f1_score: 0.5920 - lr: 0.0055\n",
      "Epoch 5/8\n",
      "5625/5625 [==============================] - 85s 15ms/step - loss: 0.8148 - categorical_accuracy: 0.6584 - f1_score: 0.6574 - val_loss: 0.9633 - val_categorical_accuracy: 0.5971 - val_f1_score: 0.5946 - lr: 0.0045\n",
      "Epoch 6/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.7653 - categorical_accuracy: 0.6837 - f1_score: 0.6829 - val_loss: 1.0140 - val_categorical_accuracy: 0.5938 - val_f1_score: 0.5910 - lr: 0.0037\n",
      "Epoch 7/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.7148 - categorical_accuracy: 0.7098 - f1_score: 0.7092 - val_loss: 1.0455 - val_categorical_accuracy: 0.5890 - val_f1_score: 0.5869 - lr: 0.0030\n",
      "Epoch 8/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.6641 - categorical_accuracy: 0.7345 - f1_score: 0.7340 - val_loss: 1.1238 - val_categorical_accuracy: 0.5839 - val_f1_score: 0.5823 - lr: 0.0025\n",
      "cnn3\n",
      "Epoch 1/8\n",
      "5625/5625 [==============================] - 92s 16ms/step - loss: 1.0362 - categorical_accuracy: 0.5545 - f1_score: 0.5503 - val_loss: 0.9760 - val_categorical_accuracy: 0.5813 - val_f1_score: 0.5756 - lr: 0.0100\n",
      "Epoch 2/8\n",
      "5625/5625 [==============================] - 90s 16ms/step - loss: 0.9392 - categorical_accuracy: 0.5978 - f1_score: 0.5958 - val_loss: 0.9530 - val_categorical_accuracy: 0.5914 - val_f1_score: 0.5843 - lr: 0.0082\n",
      "Epoch 3/8\n",
      "5625/5625 [==============================] - 90s 16ms/step - loss: 0.8924 - categorical_accuracy: 0.6204 - f1_score: 0.6189 - val_loss: 0.9411 - val_categorical_accuracy: 0.5995 - val_f1_score: 0.5947 - lr: 0.0067\n",
      "Epoch 4/8\n",
      "5625/5625 [==============================] - 91s 16ms/step - loss: 0.8498 - categorical_accuracy: 0.6407 - f1_score: 0.6395 - val_loss: 0.9441 - val_categorical_accuracy: 0.6008 - val_f1_score: 0.5971 - lr: 0.0055\n",
      "Epoch 5/8\n",
      "5625/5625 [==============================] - 90s 16ms/step - loss: 0.8058 - categorical_accuracy: 0.6620 - f1_score: 0.6611 - val_loss: 0.9575 - val_categorical_accuracy: 0.5994 - val_f1_score: 0.5974 - lr: 0.0045\n",
      "Epoch 6/8\n",
      "5625/5625 [==============================] - 90s 16ms/step - loss: 0.7591 - categorical_accuracy: 0.6860 - f1_score: 0.6853 - val_loss: 0.9953 - val_categorical_accuracy: 0.5949 - val_f1_score: 0.5929 - lr: 0.0037\n",
      "Epoch 7/8\n",
      "5625/5625 [==============================] - 90s 16ms/step - loss: 0.7105 - categorical_accuracy: 0.7104 - f1_score: 0.7098 - val_loss: 1.0196 - val_categorical_accuracy: 0.5943 - val_f1_score: 0.5926 - lr: 0.0030\n",
      "Epoch 8/8\n",
      "5625/5625 [==============================] - 90s 16ms/step - loss: 0.6609 - categorical_accuracy: 0.7351 - f1_score: 0.7346 - val_loss: 1.0841 - val_categorical_accuracy: 0.5838 - val_f1_score: 0.5814 - lr: 0.0025\n",
      "cnn4\n",
      "Epoch 1/8\n",
      "5625/5625 [==============================] - 85s 15ms/step - loss: 1.0620 - categorical_accuracy: 0.5418 - f1_score: 0.5367 - val_loss: 0.9824 - val_categorical_accuracy: 0.5784 - val_f1_score: 0.5739 - lr: 0.0100\n",
      "Epoch 2/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.9537 - categorical_accuracy: 0.5913 - f1_score: 0.5891 - val_loss: 0.9570 - val_categorical_accuracy: 0.5901 - val_f1_score: 0.5872 - lr: 0.0082\n",
      "Epoch 3/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.9110 - categorical_accuracy: 0.6108 - f1_score: 0.6091 - val_loss: 0.9447 - val_categorical_accuracy: 0.5961 - val_f1_score: 0.5922 - lr: 0.0067\n",
      "Epoch 4/8\n",
      "5625/5625 [==============================] - 85s 15ms/step - loss: 0.8741 - categorical_accuracy: 0.6288 - f1_score: 0.6274 - val_loss: 0.9533 - val_categorical_accuracy: 0.5939 - val_f1_score: 0.5892 - lr: 0.0055\n",
      "Epoch 5/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.8381 - categorical_accuracy: 0.6462 - f1_score: 0.6450 - val_loss: 0.9457 - val_categorical_accuracy: 0.5992 - val_f1_score: 0.5962 - lr: 0.0045\n",
      "Epoch 6/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.7999 - categorical_accuracy: 0.6658 - f1_score: 0.6649 - val_loss: 0.9690 - val_categorical_accuracy: 0.5957 - val_f1_score: 0.5937 - lr: 0.0037\n",
      "Epoch 7/8\n",
      "5625/5625 [==============================] - 83s 15ms/step - loss: 0.7608 - categorical_accuracy: 0.6861 - f1_score: 0.6853 - val_loss: 0.9861 - val_categorical_accuracy: 0.5950 - val_f1_score: 0.5932 - lr: 0.0030\n",
      "Epoch 8/8\n",
      "5625/5625 [==============================] - 84s 15ms/step - loss: 0.7204 - categorical_accuracy: 0.7067 - f1_score: 0.7061 - val_loss: 1.0220 - val_categorical_accuracy: 0.5898 - val_f1_score: 0.5886 - lr: 0.0025\n"
     ]
    }
   ],
   "source": [
    "model_list = [cnn1, cnn2, cnn3, cnn4]\n",
    "\n",
    "params=[\n",
    "    {\"dropout_rate\": .0,\"kernel_regularizer\": None, \"bias_regularizer\": None, \"activity_regularizer\": None},\n",
    "]\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.2)\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    for model_obj in model_list:\n",
    "        for param in params:\n",
    "\n",
    "            dropout_rate = param['dropout_rate']\n",
    "            kernel_regularizer = param['kernel_regularizer']\n",
    "            bias_regularizer = param['bias_regularizer']\n",
    "            activity_regularizer = param['activity_regularizer']\n",
    "\n",
    "            if kernel_regularizer is None:\n",
    "                regularizers_ = \"None\"\n",
    "            else:\n",
    "                regularizers_ = \"L1L2\"\n",
    "            if dropout_rate == .0:\n",
    "                dropout = \"0\"\n",
    "            else:\n",
    "                dropout = f\"{dropout_rate}\"\n",
    "\n",
    "            model = model_obj.model(vocabulary, dropout_rate, kernel_regularizer, bias_regularizer, activity_regularizer)\n",
    "            model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.01),\n",
    "                           loss=keras.losses.categorical_crossentropy,\n",
    "                           metrics=[keras.metrics.categorical_accuracy, tfa.metrics.F1Score(num_classes=6, average='weighted')]\n",
    "                           )\n",
    "            print(model.name)\n",
    "\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/{dropout}\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/{dropout}\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}\")\n",
    "\n",
    "            if not os.path.exists(f\"logs/{model.name}/\"):\n",
    "                os.mkdir(f\"logs/{model.name}\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/{dropout}\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/{dropout}\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}\")\n",
    "\n",
    "            # if not os.path.exists(f\"logs/{model.name}/{epsilone}\"):\n",
    "            #     os.mkdir(f\"logs/{model.name}/{epsilone}\")\n",
    "\n",
    "            chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}/model.h5',\n",
    "            monitor='val_f1_score', mode='max', save_best_only=True)\n",
    "\n",
    "            sheduler = keras.callbacks.LearningRateScheduler(scheduler,0)\n",
    "            stop_nan = keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}/\")\n",
    "            #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}/{seed}/{epsilone}/\")\n",
    "            model.fit(x=train_in, y=train_out, validation_data=(validation_in, validation_out), batch_size=128, epochs=8, callbacks=[sheduler, stop_nan, chekpoint, tensorboard_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = model.predict(train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_res = model.predict(validation_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_out = np.argmax(validation_out, axis=1)\n",
    "train_out = np.argmax(train_out, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test[['read_at','date_added','date_updated' ,'started_at']] = test[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)\n",
    "\n",
    "test_data = [test['review_text'], test['n_comments'], test['n_votes'], test['read_at'], test['date_added'], test['date_updated'], test['started_at']]\n",
    "restest = model.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = []\n",
    "for line in tqdm(val_res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "val_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "test_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "train_data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(train_out, train_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(val_out, val_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['rating'] = test_data\n",
    "\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])\n",
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('submission_unet5_embedding_class_weights_model.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.save('unet5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
