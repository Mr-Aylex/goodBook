{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "#import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open dataset\n"
     ]
    }
   ],
   "source": [
    "#read train dataset\n",
    "print(\"open dataset\")\n",
    "train = pd.read_csv(\"../dataset/goodreads_train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load a np_archive of review_text col of train dataset preprocess in main.py\n",
    "train_prepro = pd.DataFrame(data=np.load(file=\"../vocabulaires/prepro_train_archive_PN_less.npy\", allow_pickle=True), columns=['review_text'])['review_text']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# add review text col to train dataset\n",
    "train['review_text'] = train_prepro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   30988\n",
      "1   28718\n",
      "2   72627\n",
      "3   188972\n",
      "4   313688\n",
      "5   265007\n"
     ]
    }
   ],
   "source": [
    "print(\"0  \",train[train['rating'] == 0][\"rating\"].count())\n",
    "print(\"1  \", train[train['rating'] == 1][\"rating\"].count())\n",
    "print(\"2  \", train[train['rating'] == 2][\"rating\"].count())\n",
    "print(\"3  \", train[train['rating'] == 3][\"rating\"].count())\n",
    "print(\"4  \", train[train['rating'] == 4][\"rating\"].count())\n",
    "print(\"5  \", train[train['rating'] == 5][\"rating\"].count())\n",
    "#train_3_5 = train[train['rating'] >= 3]\n",
    "#train['rating'] = train['rating'].apply(lambda x: x-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "rating = keras.utils.to_categorical(train['rating'], num_classes=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = tf.random.shuffle(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#create model layers\n",
    "inputs = keras.Input(shape=(1,), dtype=tf.string) # text\n",
    "inputs2 = keras.Input(shape=1, dtype=tf.int64) # n_comment\n",
    "inputs3 = keras.Input(shape=1, dtype=tf.int64) # n_votes\n",
    "#create vectorize layer, to transform words in integer\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1400,\n",
    "    vocabulary=np.load('../vocabulaires/voc_lemm_without_NP.npy')\n",
    ")(inputs)\n",
    "conc = keras.layers.concatenate([vectorize_layer, inputs2,inputs3])\n",
    "layer1 = keras.layers.Dense(300, activation=tf.keras.activations.relu)(conc)\n",
    "layer2 = keras.layers.Dense(300, activation=tf.keras.activations.relu)(layer1)\n",
    "layer3 = keras.layers.Dense(300, activation=tf.keras.activations.relu)(layer2)\n",
    "layer4 = keras.layers.Dense(300, activation=tf.keras.activations.relu)(layer3)\n",
    "outputs = keras.layers.Dense(6, activation=tf.keras.activations.softmax)(layer4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[inputs, inputs2, inputs3], outputs=outputs, name=\"mnist_model\")\n",
    "tensorboard = TensorBoard(log_dir=\"logs\".format(time()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8287/18000 [============>.................] - ETA: 58s - loss: 0.3940 - categorical_accuracy: 0.3482"
     ]
    }
   ],
   "source": [
    "#learning_rates = [0.01, 0.001, 0.000001, 0.0000001]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 107s 6ms/step - loss: 0.8585 - categorical_accuracy: 0.3442\n",
      "Epoch 2/20\n",
      "18000/18000 [==============================] - 101s 6ms/step - loss: 0.4192 - categorical_accuracy: 0.3484\n",
      "Epoch 3/20\n",
      "18000/18000 [==============================] - 103s 6ms/step - loss: 0.4075 - categorical_accuracy: 0.3485\n",
      "Epoch 4/20\n",
      "18000/18000 [==============================] - 102s 6ms/step - loss: 0.5234 - categorical_accuracy: 0.3486\n",
      "Epoch 5/20\n",
      "18000/18000 [==============================] - 112s 6ms/step - loss: 0.4929 - categorical_accuracy: 0.3486\n",
      "Epoch 6/20\n",
      " 9076/18000 [==============>...............] - ETA: 58s - loss: 0.3945 - categorical_accuracy: 0.3487"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#for learning_rate in learning_rates:\u001B[39;00m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(),\n\u001B[0;32m      3\u001B[0m               loss\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mbinary_crossentropy,\n\u001B[0;32m      4\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mcategorical_accuracy]\n\u001B[0;32m      5\u001B[0m               )\n\u001B[1;32m----> 6\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mreview_text\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mn_comments\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mn_votes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrating\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                      \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensorBoard\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlog_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../logs/relu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                  \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                  \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2494\u001B[0m   (graph_function,\n\u001B[0;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1865\u001B[0m     args,\n\u001B[0;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1867\u001B[0m     executing_eagerly)\n\u001B[0;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#for learning_rate in learning_rates:\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy]\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  403/18000 [..............................] - ETA: 1:45 - loss: 19.8887 - categorical_accuracy: 0.2680"
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit([train['review_text'], train['n_comments'], train['n_votes']], rating, epochs=20,\n",
    "                  callbacks=[\n",
    "                      tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "                  ],\n",
    "                  batch_size=100\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#model.save(\"../models_trained/linear_model_2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "#read test dataset\n",
    "test = pd.read_csv(\"../dataset/goodreads_test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Load a np_archive of review_text col of train dataset preprocess in main.py\n",
    "test_prepro = pd.DataFrame(data=np.load(file=\"../vocabulaires/prepro_test_archive_PN_less.npy\", allow_pickle=True), columns=['review_text'])['review_text']\n",
    "test['review_text'] = test_prepro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 user_id   book_id  \\\n0       b9450d1c1f97f891c392b1105959b56e   7092507   \n1       b9450d1c1f97f891c392b1105959b56e   5576654   \n2       b9450d1c1f97f891c392b1105959b56e  15754052   \n3       b9450d1c1f97f891c392b1105959b56e     17020   \n4       b9450d1c1f97f891c392b1105959b56e  12551082   \n...                                  ...       ...   \n478028  35cef391b171b4fca45771e508028212  15745950   \n478029  35cef391b171b4fca45771e508028212  10861195   \n478030  35cef391b171b4fca45771e508028212   6131164   \n478031  35cef391b171b4fca45771e508028212  10025305   \n478032  35cef391b171b4fca45771e508028212   6482837   \n\n                               review_id  \\\n0       5c4df7e70e9b438c761f07a4620ccb7c   \n1       8eaeaf13213eeb16ad879a2a2591bbe5   \n2       dce649b733c153ba5363a0413cac988f   \n3       8a46df0bb997269d6834f9437a4b0a77   \n4       d11d3091e22f1cf3cb865598de197599   \n...                                  ...   \n478028  0e1db3d4b04256f9660f5d276ddf1314   \n478029  0b7f352e58caf0fd1f961e98ef04e89c   \n478030  9b19eff33ddb14e9e68fca2e90379e46   \n478031  8be463fed78f0da63e964706f710332b   \n478032  62ed1263c7d216986cc419cd4e8a408b   \n\n                                              review_text  \\\n0       * spoiler alert this definitely one favorite a...   \n1       * spoiler alert `` you drink . '' i 'm huge fa...   \n2       one favorite character under i 'm happy read s...   \n3       * spoiler alert if feel like travelling n't mo...   \n4       3.5 star i read enjoyed first two novel series...   \n...                                                   ...   \n478028                    n't wait ' before ... after ...   \n478029  to-read shelf forever . update i 've finished ...   \n478030  the last book left wanting . i need happy endi...   \n478031  things heating second novel devices . will beg...   \n478032  before i even start review , i must say word t...   \n\n                            date_added                    date_updated  \\\n0       Sat Nov 10 06:06:13 -0800 2012  Sun Nov 11 05:38:36 -0800 2012   \n1       Fri Nov 09 21:55:16 -0800 2012  Sat Nov 10 05:41:49 -0800 2012   \n2       Fri Nov 09 00:25:50 -0800 2012  Sat Nov 10 06:14:10 -0800 2012   \n3       Thu Nov 01 00:28:39 -0700 2012  Sat Nov 03 11:35:22 -0700 2012   \n4       Thu Oct 18 00:57:00 -0700 2012  Mon Apr 01 23:00:51 -0700 2013   \n...                                ...                             ...   \n478028  Sun Aug 05 10:26:12 -0700 2012  Tue Apr 16 17:24:00 -0700 2013   \n478029  Tue Jul 10 23:31:00 -0700 2012  Fri Dec 28 20:05:51 -0800 2012   \n478030  Tue Jul 10 19:45:17 -0700 2012  Mon Mar 25 18:41:51 -0700 2013   \n478031  Thu Jul 05 19:19:30 -0700 2012  Thu Jan 24 16:24:54 -0800 2013   \n478032  Mon Jun 04 18:06:26 -0700 2012  Sat Dec 29 17:47:56 -0800 2012   \n\n                               read_at                      started_at  \\\n0       Sun Nov 11 05:38:36 -0800 2012  Sat Nov 10 00:00:00 -0800 2012   \n1       Sat Nov 10 05:41:49 -0800 2012  Fri Nov 09 00:00:00 -0800 2012   \n2       Sat Nov 10 06:14:10 -0800 2012  Fri Nov 09 00:00:00 -0800 2012   \n3       Sat Nov 03 11:35:22 -0700 2012  Thu Nov 01 00:00:00 -0700 2012   \n4       Sat Mar 30 00:00:00 -0700 2013  Fri Mar 29 00:00:00 -0700 2013   \n...                                ...                             ...   \n478028  Tue Apr 16 00:00:00 -0700 2013                             NaN   \n478029                             NaN                             NaN   \n478030  Tue Mar 19 00:00:00 -0700 2013                             NaN   \n478031  Mon Jan 14 00:00:00 -0800 2013                             NaN   \n478032                             NaN                             NaN   \n\n        n_votes  n_comments  \n0             1           0  \n1             1           0  \n2             0           0  \n3             0           0  \n4             0           0  \n...         ...         ...  \n478028        0           0  \n478029        0           0  \n478030        0           0  \n478031        0           0  \n478032        0           0  \n\n[478033 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>7092507</td>\n      <td>5c4df7e70e9b438c761f07a4620ccb7c</td>\n      <td>* spoiler alert this definitely one favorite a...</td>\n      <td>Sat Nov 10 06:06:13 -0800 2012</td>\n      <td>Sun Nov 11 05:38:36 -0800 2012</td>\n      <td>Sun Nov 11 05:38:36 -0800 2012</td>\n      <td>Sat Nov 10 00:00:00 -0800 2012</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>5576654</td>\n      <td>8eaeaf13213eeb16ad879a2a2591bbe5</td>\n      <td>* spoiler alert `` you drink . '' i 'm huge fa...</td>\n      <td>Fri Nov 09 21:55:16 -0800 2012</td>\n      <td>Sat Nov 10 05:41:49 -0800 2012</td>\n      <td>Sat Nov 10 05:41:49 -0800 2012</td>\n      <td>Fri Nov 09 00:00:00 -0800 2012</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>15754052</td>\n      <td>dce649b733c153ba5363a0413cac988f</td>\n      <td>one favorite character under i 'm happy read s...</td>\n      <td>Fri Nov 09 00:25:50 -0800 2012</td>\n      <td>Sat Nov 10 06:14:10 -0800 2012</td>\n      <td>Sat Nov 10 06:14:10 -0800 2012</td>\n      <td>Fri Nov 09 00:00:00 -0800 2012</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>17020</td>\n      <td>8a46df0bb997269d6834f9437a4b0a77</td>\n      <td>* spoiler alert if feel like travelling n't mo...</td>\n      <td>Thu Nov 01 00:28:39 -0700 2012</td>\n      <td>Sat Nov 03 11:35:22 -0700 2012</td>\n      <td>Sat Nov 03 11:35:22 -0700 2012</td>\n      <td>Thu Nov 01 00:00:00 -0700 2012</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>12551082</td>\n      <td>d11d3091e22f1cf3cb865598de197599</td>\n      <td>3.5 star i read enjoyed first two novel series...</td>\n      <td>Thu Oct 18 00:57:00 -0700 2012</td>\n      <td>Mon Apr 01 23:00:51 -0700 2013</td>\n      <td>Sat Mar 30 00:00:00 -0700 2013</td>\n      <td>Fri Mar 29 00:00:00 -0700 2013</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>478028</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>15745950</td>\n      <td>0e1db3d4b04256f9660f5d276ddf1314</td>\n      <td>n't wait ' before ... after ...</td>\n      <td>Sun Aug 05 10:26:12 -0700 2012</td>\n      <td>Tue Apr 16 17:24:00 -0700 2013</td>\n      <td>Tue Apr 16 00:00:00 -0700 2013</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478029</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>10861195</td>\n      <td>0b7f352e58caf0fd1f961e98ef04e89c</td>\n      <td>to-read shelf forever . update i 've finished ...</td>\n      <td>Tue Jul 10 23:31:00 -0700 2012</td>\n      <td>Fri Dec 28 20:05:51 -0800 2012</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478030</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>6131164</td>\n      <td>9b19eff33ddb14e9e68fca2e90379e46</td>\n      <td>the last book left wanting . i need happy endi...</td>\n      <td>Tue Jul 10 19:45:17 -0700 2012</td>\n      <td>Mon Mar 25 18:41:51 -0700 2013</td>\n      <td>Tue Mar 19 00:00:00 -0700 2013</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478031</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>10025305</td>\n      <td>8be463fed78f0da63e964706f710332b</td>\n      <td>things heating second novel devices . will beg...</td>\n      <td>Thu Jul 05 19:19:30 -0700 2012</td>\n      <td>Thu Jan 24 16:24:54 -0800 2013</td>\n      <td>Mon Jan 14 00:00:00 -0800 2013</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478032</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>6482837</td>\n      <td>62ed1263c7d216986cc419cd4e8a408b</td>\n      <td>before i even start review , i must say word t...</td>\n      <td>Mon Jun 04 18:06:26 -0700 2012</td>\n      <td>Sat Dec 29 17:47:56 -0800 2012</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>478033 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28125/28125 [==============================] - 149s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# test the model with test dataset\n",
    "res = model.predict([train['review_text'], train['n_comments'], train['n_votes']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.02655727, 0.0254236 , 0.06662676, 0.19006895, 0.39853317,\n        0.29279023],\n       [0.02655727, 0.0254236 , 0.06662676, 0.19006895, 0.39853317,\n        0.29279023],\n       [0.02655727, 0.0254236 , 0.06662676, 0.19006895, 0.39853317,\n        0.29279023],\n       ...,\n       [0.02655727, 0.0254236 , 0.06662676, 0.19006895, 0.39853317,\n        0.29279023],\n       [0.02655727, 0.0254236 , 0.06662676, 0.19006895, 0.39853317,\n        0.29279023],\n       [0.02655727, 0.0254236 , 0.06662676, 0.19006895, 0.39853317,\n        0.29279023]], dtype=float32)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14939/14939 [==============================] - 47s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "restest = model.predict([test['review_text'], test['n_comments'], test['n_votes']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/478033 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "584da2ee910e4c4da84198ae83b26e3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reverse keras.utils.to_categorical for kaggle submission\n",
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "test['rating'] = data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# create a dataframe for kaggle\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# create a csv for submission\n",
    "df.to_csv('pmc3_model.csv',index=False )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
