{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open dataset\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from multiprocessing import  Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from keras.layers import Dense, Dropout\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from time import time\n",
    "print(\"open dataset\")\n",
    "train = pd.read_csv(\"../dataset/goodreads_train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "train_prepro = pd.DataFrame(data=np.load(file = \"C:/Users/alhus/PycharmProjects/goodBook/prepro_train_archive_PN_less.npy\", allow_pickle=True), columns=['review_text'])['review_text']\n",
    "# test = pd.read_csv(\"dataset/goodreads_test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "0         this special book . it started slow first thir...\n1         recommended . free : http : //www.audible.com/...\n2         a fun , fast paced science fiction thriller . ...\n3         recommended reading understand going middle am...\n4         i really enjoyed book , lot recommend . it dra...\n                                ...                        \n899995    3.5 star . popular author agent want character...\n899996    this quick read . i read lot book recently one...\n899997    * spoiler alert * 3.5 star . this book sweet i...\n899998    * spoiler alert another fun read ! 's new assi...\n899999    * spoiler alert * 3.5 star i liked ! the story...\nName: review_text, Length: 900000, dtype: object"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prepro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "train['review_text'] = train_prepro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "0         this special book . it started slow first thir...\n1         recommended . free : http : //www.audible.com/...\n2         a fun , fast paced science fiction thriller . ...\n3         recommended reading understand going middle am...\n4         i really enjoyed book , lot recommend . it dra...\n                                ...                        \n899995    3.5 star . popular author agent want character...\n899996    this quick read . i read lot book recently one...\n899997    * spoiler alert * 3.5 star . this book sweet i...\n899998    * spoiler alert another fun read ! 's new assi...\n899999    * spoiler alert * 3.5 star i liked ! the story...\nName: review_text, Length: 900000, dtype: object"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['review_text']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   30988\n",
      "1   28718\n",
      "2   72627\n",
      "3   188972\n",
      "4   313688\n",
      "5   265007\n"
     ]
    }
   ],
   "source": [
    "print(\"0  \",train[train['rating'] == 0][\"rating\"].count())\n",
    "print(\"1  \", train[train['rating'] == 1][\"rating\"].count())\n",
    "print(\"2  \", train[train['rating'] == 2][\"rating\"].count())\n",
    "print(\"3  \", train[train['rating'] == 3][\"rating\"].count())\n",
    "print(\"4  \", train[train['rating'] == 4][\"rating\"].count())\n",
    "print(\"5  \", train[train['rating'] == 5][\"rating\"].count())\n",
    "#train_3_5 = train[train['rating'] >= 3]\n",
    "#train['rating'] = train['rating'].apply(lambda x: x-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "#train = train[train['rating'] >= 3]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "rating = keras.utils.to_categorical(train['rating'], num_classes=6)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "rating = rating.astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "numpy.ndarray"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rating)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "mylen = len(np.load('C:/Users/alhus/PycharmProjects/goodBook/voc_lemm_without_NP.npy'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "391582"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mylen"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(1,), dtype=tf.string)\n",
    "\"\"\"inputs2 = keras.Input(shape=(1), dtype=tf.int64)\n",
    "inputs3 = keras.Input(shape=(1), dtype=tf.int64)\"\"\"\n",
    "\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1400,\n",
    "    vocabulary=np.load('C:/Users/alhus/PycharmProjects/goodBook/voc_lemm_without_NP.npy')\n",
    ")(inputs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([None, 1400])"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "#conc = keras.layers.concatenate([vectorize_layer])\n",
    "\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=mylen+1,output_dim=64,mask_zero=True)(vectorize_layer)\n",
    "flattened_layer = keras.layers.Flatten()(embedding_layer)\n",
    "layer1 = keras.layers.Dense(64, activation=tf.keras.activations.tanh)(flattened_layer)\n",
    "layer2 = keras.layers.Dense(32, activation=tf.keras.activations.tanh)(layer1)\n",
    "layer3 = keras.layers.Dense(32, activation=tf.keras.activations.tanh)(layer2)\n",
    "layer4 = keras.layers.Dense(16, activation=tf.keras.activations.tanh)(layer3)\n",
    "\n",
    "\n",
    "outputs = keras.layers.Dense(6, activation=tf.keras.activations.softmax)(layer4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([None, 6])"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[inputs], outputs=outputs, name=\"mnist_model\")\n",
    "tensorboard = TensorBoard(log_dir=\"../logs/relu\".format(time()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "#learning_rates = [0.01, 0.001, 0.000001, 0.0000001]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "#for learning_rate in learning_rates:\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy]\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "x_val = train['review_text'][-10000:]\n",
    "y_val = rating[-10000:]\n",
    "x_train = train['review_text'][:-10000]\n",
    "y_train = rating[:-10000]\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',classes= np.unique(train['rating']), y = train['rating'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "weight = {i : class_weights[i] for i in range(6)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 4.8405834516587065,\n 1: 5.223204958562574,\n 2: 2.0653475980007436,\n 3: 0.7937683889676778,\n 4: 0.4781821427660605,\n 5: 0.5660227843038108}"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "900/900 [==============================] - 57s 63ms/step - loss: 1.6377 - categorical_accuracy: 0.2504 - val_loss: 1.3031 - val_categorical_accuracy: 0.4549\n",
      "Epoch 2/10\n",
      "900/900 [==============================] - 55s 62ms/step - loss: 1.2525 - categorical_accuracy: 0.4747 - val_loss: 1.1553 - val_categorical_accuracy: 0.5246\n",
      "Epoch 3/10\n",
      "900/900 [==============================] - 54s 60ms/step - loss: 1.1131 - categorical_accuracy: 0.5243 - val_loss: 1.0109 - val_categorical_accuracy: 0.6003\n",
      "Epoch 4/10\n",
      "900/900 [==============================] - 55s 61ms/step - loss: 0.9301 - categorical_accuracy: 0.5896 - val_loss: 0.8940 - val_categorical_accuracy: 0.6598\n",
      "Epoch 5/10\n",
      "900/900 [==============================] - 55s 61ms/step - loss: 0.7458 - categorical_accuracy: 0.6594 - val_loss: 0.7546 - val_categorical_accuracy: 0.7201\n",
      "Epoch 6/10\n",
      "900/900 [==============================] - 54s 60ms/step - loss: 0.6045 - categorical_accuracy: 0.7160 - val_loss: 0.6554 - val_categorical_accuracy: 0.7574\n",
      "Epoch 7/10\n",
      "900/900 [==============================] - 55s 61ms/step - loss: 0.5073 - categorical_accuracy: 0.7585 - val_loss: 0.5555 - val_categorical_accuracy: 0.7961\n",
      "Epoch 8/10\n",
      "900/900 [==============================] - 54s 60ms/step - loss: 0.4421 - categorical_accuracy: 0.7895 - val_loss: 0.5043 - val_categorical_accuracy: 0.8155\n",
      "Epoch 9/10\n",
      "900/900 [==============================] - 53s 59ms/step - loss: 0.3960 - categorical_accuracy: 0.8118 - val_loss: 0.4629 - val_categorical_accuracy: 0.8293\n",
      "Epoch 10/10\n",
      "900/900 [==============================] - 57s 63ms/step - loss: 0.3618 - categorical_accuracy: 0.8287 - val_loss: 0.4256 - val_categorical_accuracy: 0.8451\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2602313e470>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train['review_text'], rating, epochs=10,\n",
    "                  callbacks=[\n",
    "                      tf.keras.callbacks.TensorBoard(log_dir=\"../logs/relu\"),\n",
    "                  ],\n",
    "                  batch_size=1000, validation_data=[x_val, y_val], shuffle= True, class_weight= weight\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models_trained/PMC_embedding_model_10_class_weights\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models_trained/PMC_embedding_model_10_class_weights\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"../dataset/goodreads_test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "test_prepro = pd.DataFrame(data=np.load(file=\"C:/Users/alhus/PycharmProjects/goodBook/prepro_test_archive_PN_less.npy\", allow_pickle=True), columns=['review_text'])['review_text']\n",
    "test['review_text'] = test_prepro"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 user_id   book_id  \\\n0       b9450d1c1f97f891c392b1105959b56e   7092507   \n1       b9450d1c1f97f891c392b1105959b56e   5576654   \n2       b9450d1c1f97f891c392b1105959b56e  15754052   \n3       b9450d1c1f97f891c392b1105959b56e     17020   \n4       b9450d1c1f97f891c392b1105959b56e  12551082   \n...                                  ...       ...   \n478028  35cef391b171b4fca45771e508028212  15745950   \n478029  35cef391b171b4fca45771e508028212  10861195   \n478030  35cef391b171b4fca45771e508028212   6131164   \n478031  35cef391b171b4fca45771e508028212  10025305   \n478032  35cef391b171b4fca45771e508028212   6482837   \n\n                               review_id  \\\n0       5c4df7e70e9b438c761f07a4620ccb7c   \n1       8eaeaf13213eeb16ad879a2a2591bbe5   \n2       dce649b733c153ba5363a0413cac988f   \n3       8a46df0bb997269d6834f9437a4b0a77   \n4       d11d3091e22f1cf3cb865598de197599   \n...                                  ...   \n478028  0e1db3d4b04256f9660f5d276ddf1314   \n478029  0b7f352e58caf0fd1f961e98ef04e89c   \n478030  9b19eff33ddb14e9e68fca2e90379e46   \n478031  8be463fed78f0da63e964706f710332b   \n478032  62ed1263c7d216986cc419cd4e8a408b   \n\n                                              review_text  \\\n0       * spoiler alert this definitely one favorite a...   \n1       * spoiler alert `` you drink . '' i 'm huge fa...   \n2       one favorite character under i 'm happy read s...   \n3       * spoiler alert if feel like travelling n't mo...   \n4       3.5 star i read enjoyed first two novel series...   \n...                                                   ...   \n478028                    n't wait ' before ... after ...   \n478029  to-read shelf forever . update i 've finished ...   \n478030  the last book left wanting . i need happy endi...   \n478031  things heating second novel devices . will beg...   \n478032  before i even start review , i must say word t...   \n\n                            date_added                    date_updated  \\\n0       Sat Nov 10 06:06:13 -0800 2012  Sun Nov 11 05:38:36 -0800 2012   \n1       Fri Nov 09 21:55:16 -0800 2012  Sat Nov 10 05:41:49 -0800 2012   \n2       Fri Nov 09 00:25:50 -0800 2012  Sat Nov 10 06:14:10 -0800 2012   \n3       Thu Nov 01 00:28:39 -0700 2012  Sat Nov 03 11:35:22 -0700 2012   \n4       Thu Oct 18 00:57:00 -0700 2012  Mon Apr 01 23:00:51 -0700 2013   \n...                                ...                             ...   \n478028  Sun Aug 05 10:26:12 -0700 2012  Tue Apr 16 17:24:00 -0700 2013   \n478029  Tue Jul 10 23:31:00 -0700 2012  Fri Dec 28 20:05:51 -0800 2012   \n478030  Tue Jul 10 19:45:17 -0700 2012  Mon Mar 25 18:41:51 -0700 2013   \n478031  Thu Jul 05 19:19:30 -0700 2012  Thu Jan 24 16:24:54 -0800 2013   \n478032  Mon Jun 04 18:06:26 -0700 2012  Sat Dec 29 17:47:56 -0800 2012   \n\n                               read_at                      started_at  \\\n0       Sun Nov 11 05:38:36 -0800 2012  Sat Nov 10 00:00:00 -0800 2012   \n1       Sat Nov 10 05:41:49 -0800 2012  Fri Nov 09 00:00:00 -0800 2012   \n2       Sat Nov 10 06:14:10 -0800 2012  Fri Nov 09 00:00:00 -0800 2012   \n3       Sat Nov 03 11:35:22 -0700 2012  Thu Nov 01 00:00:00 -0700 2012   \n4       Sat Mar 30 00:00:00 -0700 2013  Fri Mar 29 00:00:00 -0700 2013   \n...                                ...                             ...   \n478028  Tue Apr 16 00:00:00 -0700 2013                             NaN   \n478029                             NaN                             NaN   \n478030  Tue Mar 19 00:00:00 -0700 2013                             NaN   \n478031  Mon Jan 14 00:00:00 -0800 2013                             NaN   \n478032                             NaN                             NaN   \n\n        n_votes  n_comments  \n0             1           0  \n1             1           0  \n2             0           0  \n3             0           0  \n4             0           0  \n...         ...         ...  \n478028        0           0  \n478029        0           0  \n478030        0           0  \n478031        0           0  \n478032        0           0  \n\n[478033 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>book_id</th>\n      <th>review_id</th>\n      <th>review_text</th>\n      <th>date_added</th>\n      <th>date_updated</th>\n      <th>read_at</th>\n      <th>started_at</th>\n      <th>n_votes</th>\n      <th>n_comments</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>7092507</td>\n      <td>5c4df7e70e9b438c761f07a4620ccb7c</td>\n      <td>* spoiler alert this definitely one favorite a...</td>\n      <td>Sat Nov 10 06:06:13 -0800 2012</td>\n      <td>Sun Nov 11 05:38:36 -0800 2012</td>\n      <td>Sun Nov 11 05:38:36 -0800 2012</td>\n      <td>Sat Nov 10 00:00:00 -0800 2012</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>5576654</td>\n      <td>8eaeaf13213eeb16ad879a2a2591bbe5</td>\n      <td>* spoiler alert `` you drink . '' i 'm huge fa...</td>\n      <td>Fri Nov 09 21:55:16 -0800 2012</td>\n      <td>Sat Nov 10 05:41:49 -0800 2012</td>\n      <td>Sat Nov 10 05:41:49 -0800 2012</td>\n      <td>Fri Nov 09 00:00:00 -0800 2012</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>15754052</td>\n      <td>dce649b733c153ba5363a0413cac988f</td>\n      <td>one favorite character under i 'm happy read s...</td>\n      <td>Fri Nov 09 00:25:50 -0800 2012</td>\n      <td>Sat Nov 10 06:14:10 -0800 2012</td>\n      <td>Sat Nov 10 06:14:10 -0800 2012</td>\n      <td>Fri Nov 09 00:00:00 -0800 2012</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>17020</td>\n      <td>8a46df0bb997269d6834f9437a4b0a77</td>\n      <td>* spoiler alert if feel like travelling n't mo...</td>\n      <td>Thu Nov 01 00:28:39 -0700 2012</td>\n      <td>Sat Nov 03 11:35:22 -0700 2012</td>\n      <td>Sat Nov 03 11:35:22 -0700 2012</td>\n      <td>Thu Nov 01 00:00:00 -0700 2012</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>b9450d1c1f97f891c392b1105959b56e</td>\n      <td>12551082</td>\n      <td>d11d3091e22f1cf3cb865598de197599</td>\n      <td>3.5 star i read enjoyed first two novel series...</td>\n      <td>Thu Oct 18 00:57:00 -0700 2012</td>\n      <td>Mon Apr 01 23:00:51 -0700 2013</td>\n      <td>Sat Mar 30 00:00:00 -0700 2013</td>\n      <td>Fri Mar 29 00:00:00 -0700 2013</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>478028</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>15745950</td>\n      <td>0e1db3d4b04256f9660f5d276ddf1314</td>\n      <td>n't wait ' before ... after ...</td>\n      <td>Sun Aug 05 10:26:12 -0700 2012</td>\n      <td>Tue Apr 16 17:24:00 -0700 2013</td>\n      <td>Tue Apr 16 00:00:00 -0700 2013</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478029</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>10861195</td>\n      <td>0b7f352e58caf0fd1f961e98ef04e89c</td>\n      <td>to-read shelf forever . update i 've finished ...</td>\n      <td>Tue Jul 10 23:31:00 -0700 2012</td>\n      <td>Fri Dec 28 20:05:51 -0800 2012</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478030</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>6131164</td>\n      <td>9b19eff33ddb14e9e68fca2e90379e46</td>\n      <td>the last book left wanting . i need happy endi...</td>\n      <td>Tue Jul 10 19:45:17 -0700 2012</td>\n      <td>Mon Mar 25 18:41:51 -0700 2013</td>\n      <td>Tue Mar 19 00:00:00 -0700 2013</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478031</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>10025305</td>\n      <td>8be463fed78f0da63e964706f710332b</td>\n      <td>things heating second novel devices . will beg...</td>\n      <td>Thu Jul 05 19:19:30 -0700 2012</td>\n      <td>Thu Jan 24 16:24:54 -0800 2013</td>\n      <td>Mon Jan 14 00:00:00 -0800 2013</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>478032</th>\n      <td>35cef391b171b4fca45771e508028212</td>\n      <td>6482837</td>\n      <td>62ed1263c7d216986cc419cd4e8a408b</td>\n      <td>before i even start review , i must say word t...</td>\n      <td>Mon Jun 04 18:06:26 -0700 2012</td>\n      <td>Sat Dec 29 17:47:56 -0800 2012</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>478033 rows Ã— 10 columns</p>\n</div>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12840/14939 [========================>.....] - ETA: 10s"
     ]
    }
   ],
   "source": [
    "restest = model.predict([test['review_text']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['rating'] = data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('submission_pmc10_embedding_class_weights_model.csv',index=False )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
