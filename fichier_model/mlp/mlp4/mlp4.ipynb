{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "#import tensorflow_addons as tfa\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from tqdm.notebook import tqdm\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open dataset\n"
     ]
    }
   ],
   "source": [
    "#read train dataset\n",
    "tf.random.set_seed(5)\n",
    "print(\"open dataset\")\n",
    "train = pd.read_csv(\"../dataset/goodreads_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a np_archive of review_text col of train dataset preprocess in main.py\n",
    "train_prepro = pd.DataFrame(data=np.load(file=\"../vocabulaires/prepro_train_archive_NEG_lem.csv.npy\", allow_pickle=True), columns=['review_text'])['review_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add review text col to train dataset\n",
    "train['review_text'] = train_prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = keras.utils.to_categorical(train['rating'], num_classes=6)\n",
    "#create model layers\n",
    "inputs = keras.Input(shape=(1,), dtype=tf.string) # text\n",
    "inputs2 = keras.Input(shape=1, dtype=tf.float32) # n_comment\n",
    "inputs3 = keras.Input(shape=1, dtype=tf.float32) # n_votes\n",
    "#create vectorize layer, to transform words in integer\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1400,\n",
    "    vocabulary=np.load('../vocabulaires/voc_lemm_without_NP.npy')\n",
    ")(inputs)\n",
    "\n",
    "embedding = keras.layers.Embedding(391583, 50, input_length=1400, batch_size=100)(vectorize_layer)\n",
    "\n",
    "flatten = keras.layers.Flatten()(embedding)\n",
    "#layer = keras.layers.Dense(200, activation=tf.keras.activations.softmax)(flatten)\n",
    "\n",
    "conc = keras.layers.concatenate([flatten, inputs2,inputs3])\n",
    "layer2 = keras.layers.Dense(300, activation=tf.keras.activations.softmax)(conc)\n",
    "layer3 = keras.layers.Dense(300, activation=tf.keras.activations.softmax)(layer2)\n",
    "outputs = keras.layers.Dense(6, activation=tf.keras.activations.relu)(layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=[inputs, inputs2, inputs3], outputs=outputs, name=\"mnist_model\")\n",
    "tensorboard = TensorBoard(log_dir=\"logs\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for learning_rate in learning_rates:\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.categorical_accuracy\n",
    "                       ], run_eagerly=True\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced',classes= np.unique(train['rating']), y = train['rating'])\n",
    "di = {}\n",
    "for i in range(len(class_weights)):\n",
    "    di[i] = class_weights[i]\n",
    "model.save(\"../models_trained/pmc4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 [==============================] - 88s 366ms/step - loss: 0.6559 - categorical_accuracy: 0.4438 - val_loss: 1.2189 - val_categorical_accuracy: 0.3685\n",
      "Epoch 2/10\n",
      "240/240 [==============================] - 89s 369ms/step - loss: 0.6496 - categorical_accuracy: 0.4795 - val_loss: 1.2384 - val_categorical_accuracy: 0.3672\n",
      "Epoch 3/10\n",
      "240/240 [==============================] - 89s 369ms/step - loss: 0.6486 - categorical_accuracy: 0.4873 - val_loss: 1.2353 - val_categorical_accuracy: 0.3530\n",
      "Epoch 4/10\n",
      "240/240 [==============================] - 88s 368ms/step - loss: 0.6450 - categorical_accuracy: 0.4921 - val_loss: 1.2447 - val_categorical_accuracy: 0.3648\n",
      "Epoch 5/10\n",
      "240/240 [==============================] - 91s 381ms/step - loss: 0.6445 - categorical_accuracy: 0.5029 - val_loss: 1.2529 - val_categorical_accuracy: 0.3711\n",
      "Epoch 6/10\n",
      "240/240 [==============================] - 92s 384ms/step - loss: 0.6423 - categorical_accuracy: 0.5046 - val_loss: 1.2587 - val_categorical_accuracy: 0.3699\n",
      "Epoch 7/10\n",
      "240/240 [==============================] - 89s 371ms/step - loss: 0.6441 - categorical_accuracy: 0.4946 - val_loss: 1.2473 - val_categorical_accuracy: 0.3685\n",
      "Epoch 8/10\n",
      "240/240 [==============================] - 88s 368ms/step - loss: 0.6463 - categorical_accuracy: 0.5115 - val_loss: 1.2382 - val_categorical_accuracy: 0.3828\n",
      "Epoch 9/10\n",
      "240/240 [==============================] - 110s 460ms/step - loss: 0.6462 - categorical_accuracy: 0.5013 - val_loss: 1.2448 - val_categorical_accuracy: 0.3691\n",
      "Epoch 10/10\n",
      "240/240 [==============================] - 72s 298ms/step - loss: 0.6387 - categorical_accuracy: 0.5079 - val_loss: 1.2634 - val_categorical_accuracy: 0.3558\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x218af9e0a90>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([train['review_text'], train['n_comments'], train['n_votes']], rating, epochs=10,\n",
    "                  callbacks=[\n",
    "                      tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "                  ],\n",
    "                  batch_size=3000, class_weight=di, shuffle=True, validation_split=0.2\n",
    "                  )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models_trained/model_with_embedding2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models_trained/pmc4_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read test dataset\n",
    "test = pd.read_csv(\"../dataset/goodreads_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a np_archive of review_text col of train dataset preprocess in main.py\n",
    "test_prepro = pd.DataFrame(data=np.load(file=\"../vocabulaires/prepro_test_archive_PN_less.npy\", allow_pickle=True), columns=['review_text'])['review_text']\n",
    "test['review_text'] = test_prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5275/14939 [=========>....................] - ETA: 2:31"
     ]
    }
   ],
   "source": [
    "restest = model.predict([test['review_text'], test['n_comments'], test['n_votes']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# reverse keras.utils.to_categorical for kaggle submission\n",
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "data = np.array(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test['rating'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# create a dataframe for kaggle\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# create a csv for submission\n",
    "df.to_csv('pmc4_model.csv',index=False )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
