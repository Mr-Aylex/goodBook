{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)\n",
    "#train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n",
    "train = shuffle(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=225000), Label(value='0 / 225000')â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c16ad05b77244d499f7f9e9aece3d62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_timestamp(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):  # parallel_apply\n",
    "        return 0.0\n",
    "    else:\n",
    "        try:\n",
    "            return float(pd.Timestamp(x).value / 10**18)\n",
    "        except:\n",
    "            return 0\n",
    "train[['read_at','date_added','date_updated' ,'started_at']] = train[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "inputs_data = train[['review_text','n_comments', 'n_votes','read_at','date_added','date_updated','started_at']]\n",
    "outputs_data = keras.utils.to_categorical(train['rating'], num_classes=6)\n",
    "train_in, validation_in, train_out, validation_out = train_test_split(inputs_data, outputs_data, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_in = [train_in['review_text'], train_in['n_comments'], train_in['n_votes'], train_in['read_at'], train_in['date_added'], train_in['date_updated'], train_in['started_at']]\n",
    "validation_in = [validation_in['review_text'], validation_in['n_comments'], validation_in['n_votes'], validation_in['read_at'], validation_in['date_added'], validation_in['date_updated'], validation_in['started_at']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trans_test\n",
      "Epoch 1/15\n",
      "5625/5625 [==============================] - 808s 144ms/step - loss: 1.1131 - categorical_accuracy: 0.5213 - f1_score: 0.5113 - val_loss: 1.0461 - val_categorical_accuracy: 0.5464 - val_f1_score: 0.5359 - lr: 0.0025\n",
      "Epoch 3/15\n",
      "5625/5625 [==============================] - 808s 144ms/step - loss: 1.0696 - categorical_accuracy: 0.5407 - f1_score: 0.5332 - val_loss: 1.0361 - val_categorical_accuracy: 0.5518 - val_f1_score: 0.5383 - lr: 0.0020\n",
      "Epoch 4/15\n",
      "5625/5625 [==============================] - 817s 145ms/step - loss: 1.0423 - categorical_accuracy: 0.5533 - f1_score: 0.5466 - val_loss: 1.0316 - val_categorical_accuracy: 0.5570 - val_f1_score: 0.5579 - lr: 0.0016\n",
      "Epoch 5/15\n",
      "5625/5625 [==============================] - 812s 144ms/step - loss: 0.9852 - categorical_accuracy: 0.5794 - f1_score: 0.5745 - val_loss: 1.0152 - val_categorical_accuracy: 0.5684 - val_f1_score: 0.5624 - lr: 9.0358e-04\n",
      "Epoch 8/15\n",
      "5625/5625 [==============================] - 814s 145ms/step - loss: 0.9719 - categorical_accuracy: 0.5872 - f1_score: 0.5827 - val_loss: 1.0120 - val_categorical_accuracy: 0.5693 - val_f1_score: 0.5658 - lr: 7.3979e-04\n",
      "Epoch 9/15\n",
      "5625/5625 [==============================] - 846s 150ms/step - loss: 0.9580 - categorical_accuracy: 0.5935 - f1_score: 0.5894 - val_loss: 1.0224 - val_categorical_accuracy: 0.5689 - val_f1_score: 0.5646 - lr: 6.0569e-04\n",
      "Epoch 10/15\n",
      "5625/5625 [==============================] - 809s 144ms/step - loss: 0.9446 - categorical_accuracy: 0.5988 - f1_score: 0.5949 - val_loss: 1.0371 - val_categorical_accuracy: 0.5663 - val_f1_score: 0.5614 - lr: 4.9590e-04\n",
      "Epoch 11/15\n",
      "5625/5625 [==============================] - 813s 145ms/step - loss: 0.9327 - categorical_accuracy: 0.6043 - f1_score: 0.6006 - val_loss: 1.0471 - val_categorical_accuracy: 0.5659 - val_f1_score: 0.5617 - lr: 4.0601e-04\n",
      "Epoch 12/15\n",
      "5625/5625 [==============================] - 803s 143ms/step - loss: 0.9233 - categorical_accuracy: 0.6091 - f1_score: 0.6055 - val_loss: 1.0703 - val_categorical_accuracy: 0.5653 - val_f1_score: 0.5620 - lr: 3.3241e-04\n",
      "Epoch 13/15\n",
      "5625/5625 [==============================] - 800s 142ms/step - loss: 0.9138 - categorical_accuracy: 0.6139 - f1_score: 0.6103 - val_loss: 1.0804 - val_categorical_accuracy: 0.5615 - val_f1_score: 0.5595 - lr: 2.7215e-04\n",
      "Epoch 14/15\n",
      "5625/5625 [==============================] - 800s 142ms/step - loss: 0.9047 - categorical_accuracy: 0.6182 - f1_score: 0.6147 - val_loss: 1.1164 - val_categorical_accuracy: 0.5599 - val_f1_score: 0.5561 - lr: 2.2282e-04\n",
      "Epoch 15/15\n",
      "5625/5625 [==============================] - 801s 142ms/step - loss: 0.8976 - categorical_accuracy: 0.6211 - f1_score: 0.6177 - val_loss: 1.1021 - val_categorical_accuracy: 0.5588 - val_f1_score: 0.5537 - lr: 1.8243e-04\n"
     ]
    }
   ],
   "source": [
    "model_list = [transf_test]\n",
    "kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "bias_regularizer=regularizers.L2(1e-4)\n",
    "activity_regularizer=regularizers.L2(1e-5)\n",
    "params=[\n",
    "    #{\"dropout_rate\": .0,\"kernel_regularizer\": None, \"bias_regularizer\": None, \"activity_regularizer\": None},\n",
    "    {\"dropout_rate\": .2,\"kernel_regularizer\": None, \"bias_regularizer\": None, \"activity_regularizer\": None},\n",
    "    #{\"dropout_rate\": .0,\"kernel_regularizer\": regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    #  \"bias_regularizer\": regularizers.L2(1e-4),\n",
    "    #  \"activity_regularizer\": regularizers.L2(1e-5)},\n",
    "    # {\"dropout_rate\": .2,\"kernel_regularizer\": regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    #  \"bias_regularizer\": regularizers.L2(1e-4),\n",
    "    #  \"activity_regularizer\": regularizers.L2(1e-5)}\n",
    "]\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.2)\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    for model_obj in model_list:\n",
    "        for param in params:\n",
    "\n",
    "            dropout_rate = param['dropout_rate']\n",
    "            kernel_regularizer = param['kernel_regularizer']\n",
    "            bias_regularizer = param['bias_regularizer']\n",
    "            activity_regularizer = param['activity_regularizer']\n",
    "\n",
    "            if kernel_regularizer is None:\n",
    "                regularizers_ = \"None\"\n",
    "            else:\n",
    "                regularizers_ = \"L1L2\"\n",
    "            if dropout_rate == .0:\n",
    "                dropout = \"0\"\n",
    "            else:\n",
    "                dropout = f\"{dropout_rate}\"\n",
    "\n",
    "            model = model_obj.model(vocabulary, dropout_rate, kernel_regularizer, bias_regularizer, activity_regularizer)\n",
    "            model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.003),\n",
    "                           loss=keras.losses.categorical_crossentropy,\n",
    "                           metrics=[keras.metrics.categorical_accuracy, tfa.metrics.F1Score(num_classes=6, average='weighted')]\n",
    "                           )\n",
    "            print(model.name)\n",
    "\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/{dropout}\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/{dropout}\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}\")\n",
    "\n",
    "            if not os.path.exists(f\"logs/{model.name}/\"):\n",
    "                os.mkdir(f\"logs/{model.name}\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/{dropout}\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/{dropout}\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}\")\n",
    "\n",
    "            chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}/model.h5',\n",
    "            monitor='val_f1_score', mode='max', save_best_only=True)\n",
    "            stop_nan = keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "            sheduler = keras.callbacks.LearningRateScheduler(scheduler,0)\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}/\")\n",
    "            model.fit(x=train_in, y=train_out, validation_data=(validation_in, validation_out), batch_size=128, epochs=15, callbacks=[sheduler, stop_nan, chekpoint, tensorboard_callback])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 157s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "res = model.predict(train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 [==============================] - 39s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "val_res = model.predict(validation_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "val_out = np.argmax(validation_out, axis=1)\n",
    "train_out = np.argmax(train_out, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=119512), Label(value='0 / 119512')â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cae4ad82531447f2b48ab77902e6f0d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14939/14939 [==============================] - 109s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test[['read_at','date_added','date_updated' ,'started_at']] = test[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)\n",
    "\n",
    "test_data = [test['review_text'], test['n_comments'], test['n_votes'], test['read_at'], test['date_added'], test['date_updated'], test['started_at']]\n",
    "restest = model.model.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/180000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697c040a9afc43a487e37d559e40b083"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/478033 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "933796d0a7f849669ed172bdfff976b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/720000 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a45c78a6abe4429b429b52aaf62e85b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ff = []\n",
    "for line in tqdm(val_res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "val_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "test_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "train_data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.44      0.55     24800\n",
      "           1       0.55      0.34      0.42     22993\n",
      "           2       0.55      0.52      0.53     58041\n",
      "           3       0.64      0.65      0.64    151064\n",
      "           4       0.63      0.72      0.67    250900\n",
      "           5       0.76      0.70      0.73    212202\n",
      "\n",
      "    accuracy                           0.66    720000\n",
      "   macro avg       0.64      0.56      0.59    720000\n",
      "weighted avg       0.66      0.66      0.66    720000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(train_out, train_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.40      0.49      6188\n",
      "           1       0.51      0.31      0.38      5725\n",
      "           2       0.50      0.47      0.48     14586\n",
      "           3       0.58      0.59      0.58     37908\n",
      "           4       0.58      0.68      0.63     62788\n",
      "           5       0.72      0.66      0.69     52805\n",
      "\n",
      "    accuracy                           0.61    180000\n",
      "   macro avg       0.59      0.51      0.54    180000\n",
      "weighted avg       0.62      0.61      0.61    180000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_out, val_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "test['rating'] = test_data\n",
    "\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])\n",
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "df.to_csv('submission_unet5_embedding_class_weights_model.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet5\\assets\n"
     ]
    }
   ],
   "source": [
    "model.model.save('unet5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
