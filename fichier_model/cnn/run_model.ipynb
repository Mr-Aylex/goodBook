{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils\n",
    "from pandarallel import pandarallel\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=16)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)\n",
    "#train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n",
    "train = shuffle(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=225000), Label(value='0 / 225000')â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4aa078591ff452b8c7620a5eb5024a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_timestamp(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):#parallel_apply\n",
    "        return 0.0\n",
    "    else:\n",
    "        try:\n",
    "            return float(pd.Timestamp(x).value / 10**18)\n",
    "        except:\n",
    "            return 0\n",
    "train[['read_at','date_added','date_updated' ,'started_at']] = train[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "inputs_data = train[['review_text','n_comments', 'n_votes','read_at','date_added','date_updated','started_at']]\n",
    "outputs_data = keras.utils.to_categorical(train['rating'], num_classes=6)\n",
    "train_in, validation_in, train_out, validation_out = train_test_split(inputs_data, outputs_data, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_in = [train_in['review_text'], train_in['n_comments'], train_in['n_votes'], train_in['read_at'], train_in['date_added'], train_in['date_updated'], train_in['started_at']]\n",
    "validation_in = [validation_in['review_text'], validation_in['n_comments'], validation_in['n_votes'], validation_in['read_at'], validation_in['date_added'], validation_in['date_updated'], validation_in['started_at']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet10\n",
      "Epoch 1/15\n",
      "5625/5625 [==============================] - 441s 77ms/step - loss: 83124712.0000 - categorical_accuracy: 0.3432 - f1_score: 0.2372 - val_loss: 1.4630 - val_categorical_accuracy: 0.3512 - val_f1_score: 0.1937 - lr: 0.0100\n",
      "Epoch 2/15\n",
      "1758/5625 [========>.....................] - ETA: 5:35 - loss: 1.4678 - categorical_accuracy: 0.3472 - f1_score: 0.2441"
     ]
    }
   ],
   "source": [
    "model_list = [unet10]\n",
    "kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "bias_regularizer=regularizers.L2(1e-4)\n",
    "activity_regularizer=regularizers.L2(1e-5)\n",
    "params=[\n",
    "    #{\"dropout_rate\": .15,\"kernel_regularizer\": None, \"bias_regularizer\": None, \"activity_regularizer\": None},\n",
    "\n",
    "     #{\"dropout_rate\": .3,\"kernel_regularizer\": None, \"bias_regularizer\": None, \"activity_regularizer\": None},\n",
    "    # {\"dropout_rate\": .0,\"kernel_regularizer\": regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "    #  \"bias_regularizer\": regularizers.L2(1e-4),\n",
    "    #  \"activity_regularizer\": regularizers.L2(1e-5)},\n",
    "     {\"dropout_rate\": .15,\"kernel_regularizer\": regularizers.L1L2(l1=1e-6, l2=1e-5),\n",
    "      \"bias_regularizer\": regularizers.L2(1e-5),\n",
    "      \"activity_regularizer\": regularizers.L2(1e-6)}\n",
    "]\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    for model_obj in model_list:\n",
    "        for param in params:\n",
    "\n",
    "            dropout_rate = param['dropout_rate']\n",
    "            kernel_regularizer = param['kernel_regularizer']\n",
    "            bias_regularizer = param['bias_regularizer']\n",
    "            activity_regularizer = param['activity_regularizer']\n",
    "\n",
    "            if kernel_regularizer is None:\n",
    "                regularizers_ = \"None\"\n",
    "            else:\n",
    "                regularizers_ = \"L1L2\"\n",
    "            if dropout_rate == .0:\n",
    "                dropout = \"0\"\n",
    "            else:\n",
    "                dropout = f\"{dropout_rate}\"\n",
    "\n",
    "            model = model_obj.model(vocabulary, dropout_rate, kernel_regularizer, bias_regularizer, activity_regularizer)\n",
    "            model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.01),\n",
    "                           loss=keras.losses.categorical_crossentropy,\n",
    "                           metrics=[keras.metrics.categorical_accuracy, tfa.metrics.F1Score(num_classes=6, average='weighted')]\n",
    "                           )\n",
    "            print(model.name)\n",
    "            print(model.summary())\n",
    "\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/{dropout}\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/{dropout}\")\n",
    "            if not os.path.exists(f\"checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}\"):\n",
    "                os.mkdir(f\"checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}\")\n",
    "\n",
    "            if not os.path.exists(f\"logs/{model.name}/\"):\n",
    "                os.mkdir(f\"logs/{model.name}\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/{dropout}\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/{dropout}\")\n",
    "            if not os.path.exists(f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}\"):\n",
    "                os.mkdir(f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}\")\n",
    "\n",
    "            # if not os.path.exists(f\"logs/{model.name}/{epsilone}\"):\n",
    "            #     os.mkdir(f\"logs/{model.name}/{epsilone}\")\n",
    "\n",
    "            chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/{model.name}/{seed}/{dropout}/{regularizers_}/model.h5',\n",
    "            monitor='val_f1_score', mode='max', save_best_only=True)\n",
    "\n",
    "            sheduler = keras.callbacks.LearningRateScheduler(scheduler,0)\n",
    "            stop_nan = keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}/{seed}/{dropout}/{regularizers_}/\")\n",
    "            #tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}/{seed}/{epsilone}/\")\n",
    "            model.fit(x=train_in, y=train_out, validation_data=(validation_in, validation_out), batch_size=128, epochs=15, callbacks=[sheduler, stop_nan])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = unet5.Model(vocabulary)\n",
    "model.model.load_weights('checkpoint/unet5/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = model.model.predict(train_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_res = model.model.predict(validation_in)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_out = np.argmax(validation_out, axis=1)\n",
    "train_out = np.argmax(train_out, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test[['read_at','date_added','date_updated' ,'started_at']] = test[['read_at','date_added','date_updated' ,'started_at']].parallel_applymap(convert_timestamp)\n",
    "\n",
    "test_data = [test['review_text'], test['n_comments'], test['n_votes'], test['read_at'], test['date_added'], test['date_updated'], test['started_at']]\n",
    "restest = model.model.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = []\n",
    "for line in tqdm(val_res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "val_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "test_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "train_data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(train_out, train_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(val_out, val_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['rating'] = test_data\n",
    "\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])\n",
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('submission_unet5_embedding_class_weights_model.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.save('unet5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
