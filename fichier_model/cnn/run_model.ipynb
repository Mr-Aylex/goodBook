{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tf.random.set_seed(7)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "vocabulary2 = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn8_dropout\n",
      "Epoch 1/50\n",
      "480/480 [==============================] - 89s 177ms/step - loss: 2.0499 - categorical_accuracy: 0.1550 - val_loss: 1.8706 - val_categorical_accuracy: 0.1398\n",
      "Epoch 2/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.8041 - categorical_accuracy: 0.1599 - val_loss: 1.7362 - val_categorical_accuracy: 0.2019\n",
      "Epoch 3/50\n",
      "480/480 [==============================] - 83s 172ms/step - loss: 1.7012 - categorical_accuracy: 0.2377 - val_loss: 1.6674 - val_categorical_accuracy: 0.2592\n",
      "Epoch 4/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.5878 - categorical_accuracy: 0.3028 - val_loss: 1.5055 - val_categorical_accuracy: 0.3228\n",
      "Epoch 5/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.5066 - categorical_accuracy: 0.3446 - val_loss: 1.4141 - val_categorical_accuracy: 0.3900\n",
      "Epoch 6/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.4563 - categorical_accuracy: 0.3939 - val_loss: 1.3276 - val_categorical_accuracy: 0.4371\n",
      "Epoch 7/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.4153 - categorical_accuracy: 0.4269 - val_loss: 1.4036 - val_categorical_accuracy: 0.4291\n",
      "Epoch 8/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.3848 - categorical_accuracy: 0.4461 - val_loss: 1.4093 - val_categorical_accuracy: 0.4388\n",
      "Epoch 9/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.3606 - categorical_accuracy: 0.4602 - val_loss: 1.3198 - val_categorical_accuracy: 0.4717\n",
      "Epoch 10/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.3410 - categorical_accuracy: 0.4690 - val_loss: 1.3002 - val_categorical_accuracy: 0.4874\n",
      "Epoch 11/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.3193 - categorical_accuracy: 0.4788 - val_loss: 1.2461 - val_categorical_accuracy: 0.4907\n",
      "Epoch 12/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.2958 - categorical_accuracy: 0.4862 - val_loss: 1.3156 - val_categorical_accuracy: 0.4809\n",
      "Epoch 13/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.2690 - categorical_accuracy: 0.4934 - val_loss: 1.2396 - val_categorical_accuracy: 0.5076\n",
      "Epoch 14/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.2458 - categorical_accuracy: 0.4959 - val_loss: 1.2663 - val_categorical_accuracy: 0.4989\n",
      "Epoch 15/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.2223 - categorical_accuracy: 0.5029 - val_loss: 1.1979 - val_categorical_accuracy: 0.5235\n",
      "Epoch 16/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.2005 - categorical_accuracy: 0.5111 - val_loss: 1.2082 - val_categorical_accuracy: 0.5334\n",
      "Epoch 17/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.1790 - categorical_accuracy: 0.5189 - val_loss: 1.2999 - val_categorical_accuracy: 0.5050\n",
      "Epoch 18/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.1619 - categorical_accuracy: 0.5259 - val_loss: 1.2646 - val_categorical_accuracy: 0.5180\n",
      "Epoch 19/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.1388 - categorical_accuracy: 0.5334 - val_loss: 1.2384 - val_categorical_accuracy: 0.5250\n",
      "Epoch 20/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.1220 - categorical_accuracy: 0.5383 - val_loss: 1.3217 - val_categorical_accuracy: 0.5087\n",
      "Epoch 21/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 1.1017 - categorical_accuracy: 0.5448 - val_loss: 1.3207 - val_categorical_accuracy: 0.5078\n",
      "Epoch 22/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 1.0831 - categorical_accuracy: 0.5510 - val_loss: 1.2402 - val_categorical_accuracy: 0.5394\n",
      "Epoch 23/50\n",
      "480/480 [==============================] - 85s 178ms/step - loss: 1.0699 - categorical_accuracy: 0.5529 - val_loss: 1.3499 - val_categorical_accuracy: 0.5058\n",
      "Epoch 24/50\n",
      "480/480 [==============================] - 109s 228ms/step - loss: 1.0523 - categorical_accuracy: 0.5588 - val_loss: 1.2818 - val_categorical_accuracy: 0.5341\n",
      "Epoch 25/50\n",
      "480/480 [==============================] - 120s 249ms/step - loss: 1.0368 - categorical_accuracy: 0.5626 - val_loss: 1.4371 - val_categorical_accuracy: 0.4847\n",
      "Epoch 26/50\n",
      "480/480 [==============================] - 119s 249ms/step - loss: 1.0205 - categorical_accuracy: 0.5671 - val_loss: 1.3160 - val_categorical_accuracy: 0.5242\n",
      "Epoch 27/50\n",
      "480/480 [==============================] - 119s 248ms/step - loss: 1.0066 - categorical_accuracy: 0.5724 - val_loss: 1.2853 - val_categorical_accuracy: 0.5423\n",
      "Epoch 28/50\n",
      "480/480 [==============================] - 92s 192ms/step - loss: 0.9939 - categorical_accuracy: 0.5768 - val_loss: 1.5350 - val_categorical_accuracy: 0.4679\n",
      "Epoch 29/50\n",
      "480/480 [==============================] - 89s 186ms/step - loss: 0.9842 - categorical_accuracy: 0.5787 - val_loss: 1.3657 - val_categorical_accuracy: 0.5193\n",
      "Epoch 30/50\n",
      "480/480 [==============================] - 86s 179ms/step - loss: 0.9708 - categorical_accuracy: 0.5827 - val_loss: 1.4513 - val_categorical_accuracy: 0.4943\n",
      "Epoch 31/50\n",
      "480/480 [==============================] - 85s 178ms/step - loss: 0.9608 - categorical_accuracy: 0.5861 - val_loss: 1.3467 - val_categorical_accuracy: 0.5279\n",
      "Epoch 32/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.9490 - categorical_accuracy: 0.5894 - val_loss: 1.3783 - val_categorical_accuracy: 0.5196\n",
      "Epoch 33/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.9427 - categorical_accuracy: 0.5916 - val_loss: 1.3830 - val_categorical_accuracy: 0.5246\n",
      "Epoch 34/50\n",
      "480/480 [==============================] - 84s 174ms/step - loss: 0.9341 - categorical_accuracy: 0.5949 - val_loss: 1.3688 - val_categorical_accuracy: 0.5286\n",
      "Epoch 35/50\n",
      "480/480 [==============================] - 84s 174ms/step - loss: 0.9273 - categorical_accuracy: 0.5959 - val_loss: 1.4439 - val_categorical_accuracy: 0.5135\n",
      "Epoch 36/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.9206 - categorical_accuracy: 0.5980 - val_loss: 1.4052 - val_categorical_accuracy: 0.5195\n",
      "Epoch 37/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.9111 - categorical_accuracy: 0.6011 - val_loss: 1.4117 - val_categorical_accuracy: 0.5224\n",
      "Epoch 38/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.9034 - categorical_accuracy: 0.6036 - val_loss: 1.4586 - val_categorical_accuracy: 0.5078\n",
      "Epoch 39/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8983 - categorical_accuracy: 0.6049 - val_loss: 1.4342 - val_categorical_accuracy: 0.5171\n",
      "Epoch 40/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8939 - categorical_accuracy: 0.6074 - val_loss: 1.4650 - val_categorical_accuracy: 0.5123\n",
      "Epoch 41/50\n",
      "480/480 [==============================] - 83s 173ms/step - loss: 0.8881 - categorical_accuracy: 0.6095 - val_loss: 1.4986 - val_categorical_accuracy: 0.4940\n",
      "Epoch 42/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8828 - categorical_accuracy: 0.6108 - val_loss: 1.5373 - val_categorical_accuracy: 0.4864\n",
      "Epoch 43/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8786 - categorical_accuracy: 0.6132 - val_loss: 1.4398 - val_categorical_accuracy: 0.5286\n",
      "Epoch 44/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8748 - categorical_accuracy: 0.6146 - val_loss: 1.5601 - val_categorical_accuracy: 0.4990\n",
      "Epoch 45/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8691 - categorical_accuracy: 0.6169 - val_loss: 1.4905 - val_categorical_accuracy: 0.5063\n",
      "Epoch 46/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8657 - categorical_accuracy: 0.6179 - val_loss: 1.5767 - val_categorical_accuracy: 0.4854\n",
      "Epoch 47/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8586 - categorical_accuracy: 0.6201 - val_loss: 1.5486 - val_categorical_accuracy: 0.5004\n",
      "Epoch 48/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8575 - categorical_accuracy: 0.6210 - val_loss: 1.6703 - val_categorical_accuracy: 0.4726\n",
      "Epoch 49/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8551 - categorical_accuracy: 0.6228 - val_loss: 1.5246 - val_categorical_accuracy: 0.5098\n",
      "Epoch 50/50\n",
      "480/480 [==============================] - 83s 174ms/step - loss: 0.8502 - categorical_accuracy: 0.6238 - val_loss: 1.4881 - val_categorical_accuracy: 0.5237\n"
     ]
    }
   ],
   "source": [
    "#model_list = [cnn1,cnn2, cnn3,cnn4,cnn5,cnn6, cnn8, cnn9, cnn10]\n",
    "model_list = [cnn8]\n",
    "for model_obj in model_list:\n",
    "    model = model_obj.Model(vocabulary2)\n",
    "    print(model.name)\n",
    "    if not os.path.exists(f\"logs/{model.name}\"):\n",
    "        os.mkdir(f\"logs/{model.name}\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}\")\n",
    "    model.run_experiment([train['review_text'], train['n_comments'], train['n_votes']], train['rating'], epochs=50, tensorboard_callback=tensorboard_callback, batch_size=1500)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
