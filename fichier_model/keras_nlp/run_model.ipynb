{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary2 = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmo\\AppData\\Local\\Temp\\ipykernel_17268\\897452271.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_classifier2\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " text_vectorization (TextVector  (None, 256)         0           ['input_1[0][0]']                \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " token_and_position_embedding (  (None, 256, 300)    32926500    ['text_vectorization[0][0]']     \n",
      " TokenAndPositionEmbedding)                                                                       \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, 256, 300)    543000      ['token_and_position_embedding[0]\n",
      " erEncoder)                                                      [0]']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, 256, 300)    543000      ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, 256, 300)    543000      ['transformer_encoder_1[0][0]']  \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 254, 128)     115328      ['transformer_encoder_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 127, 128)     0           ['conv1d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 127, 128)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 125, 64)      24640       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 62, 64)      0           ['conv1d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 62, 64)       0           ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 60, 32)       6176        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 30, 32)      0           ['conv1d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 30, 32)       0           ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 28, 16)       1552        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 448)          0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 448)          0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           7184        ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            102         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,710,482\n",
      "Trainable params: 34,710,482\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "2880/2880 [==============================] - 704s 243ms/step - loss: 1.2054 - categorical_accuracy: 0.4766 - f1_score: 0.4616 - val_loss: 1.0741 - val_categorical_accuracy: 0.5374 - val_f1_score: 0.5317 - lr: 0.0010\n",
      "Epoch 2/4\n",
      "2880/2880 [==============================] - 677s 235ms/step - loss: 1.0620 - categorical_accuracy: 0.5433 - f1_score: 0.5380 - val_loss: 1.0496 - val_categorical_accuracy: 0.5527 - val_f1_score: 0.5484 - lr: 0.0010\n",
      "Epoch 3/4\n",
      "  60/2880 [..............................] - ETA: 7:49 - loss: 1.0333 - categorical_accuracy: 0.5575 - f1_score: 0.5542"
     ]
    }
   ],
   "source": [
    "#model_list = [cnn1,cnn2, cnn3,cnn4,cnn5,cnn6, cnn8, cnn9, cnn10]\n",
    "model_list = [transformer_classifier2]#\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    for model_obj in model_list:\n",
    "        model = model_obj.Model(vocabulary2)\n",
    "        model.model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "                           loss=keras.losses.categorical_crossentropy,\n",
    "                           metrics=[keras.metrics.categorical_accuracy, tfa.metrics.F1Score(num_classes=6, average='weighted')]\n",
    "                           )\n",
    "        print(model.name)\n",
    "        print(model.model.summary())\n",
    "        if not os.path.exists(f\"logs/{model.name}\"):\n",
    "            os.mkdir(f\"logs/{model.name}\")\n",
    "        if not os.path.exists(f\"checkpoint/{model.name}\"):\n",
    "            os.mkdir(f\"checkpoint/{model.name}\")\n",
    "        chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/{model.name}/', save_weights_only=True,\n",
    "        monitor='val_f1_score',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}\")\n",
    "        model.run_experiment([train['review_text'], train['n_comments'], train['n_votes']], train['rating'], epochs=4, callbacks=[keras.callbacks.LearningRateScheduler(scheduler,0)], batch_size=250, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.load_weights('checkpoint/unet1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = model.model.predict([train['review_text'], train['n_comments'], train['n_votes']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "restest = model.model.predict([test['review_text'], test['n_comments'], test['n_votes']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "test_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "train_data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(train['rating'], train_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['rating'] = test_data\n",
    "\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])\n",
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('submission_unet2_embedding_class_weights_model.csv',index=False )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.save('unet2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
