{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from Model import *\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow_addons as tfa\n",
    "from keras.utils import io_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../dataset/goodreads_train.csv\")\n",
    "test = pd.read_csv(\"../../dataset/goodreads_test.csv\")\n",
    "vocabulary2 = np.load('../../vocabulaires/voc_without_std_word_count_5.npy', allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carmo\\AppData\\Local\\Temp\\ipykernel_19892\\897452271.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')\n"
     ]
    }
   ],
   "source": [
    "train['review_text'] = train['review_text'].str.replace('[^\\w\\s]','')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer_classifier1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " word_piece_tokenizer (WordPiec  (None, None, 300)   0           ['input_1[0][0]']                \n",
      " eTokenizer)                                                                                      \n",
      "                                                                                                  \n",
      " token_and_position_embedding (  (None, None, 300, 3  23155500   ['word_piece_tokenizer[0][0]']   \n",
      " TokenAndPositionEmbedding)     00)                                                               \n",
      "                                                                                                  \n",
      " transformer_encoder (Transform  (None, None, 300, 3  543000     ['token_and_position_embedding[0]\n",
      " erEncoder)                     00)                              [0]']                            \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, None, 300, 3  543000     ['transformer_encoder[0][0]']    \n",
      " rmerEncoder)                   00)                                                               \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Transfo  (None, None, 300, 3  543000     ['transformer_encoder_1[0][0]']  \n",
      " rmerEncoder)                   00)                                                               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 300)         0           ['transformer_encoder_2[0][0]']  \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 300)          0           ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 6)            1806        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 24,786,306\n",
      "Trainable params: 24,786,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "7200/7200 [==============================] - 2139s 296ms/step - loss: 1.0974 - categorical_accuracy: 0.5275 - f1_score: 0.5208 - val_loss: 1.0360 - val_categorical_accuracy: 0.5524 - val_f1_score: 0.5447 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "7200/7200 [==============================] - 2133s 296ms/step - loss: 1.0014 - categorical_accuracy: 0.5707 - f1_score: 0.5674 - val_loss: 1.0053 - val_categorical_accuracy: 0.5672 - val_f1_score: 0.5623 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "7200/7200 [==============================] - 2137s 297ms/step - loss: 0.9642 - categorical_accuracy: 0.5880 - f1_score: 0.5855 - val_loss: 1.0054 - val_categorical_accuracy: 0.5664 - val_f1_score: 0.5627 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "7200/7200 [==============================] - 2132s 296ms/step - loss: 0.9239 - categorical_accuracy: 0.6071 - f1_score: 0.6052 - val_loss: 1.0262 - val_categorical_accuracy: 0.5641 - val_f1_score: 0.5629 - lr: 9.0484e-04\n",
      "Epoch 5/10\n",
      "7200/7200 [==============================] - 2132s 296ms/step - loss: 0.8741 - categorical_accuracy: 0.6300 - f1_score: 0.6287 - val_loss: 1.0501 - val_categorical_accuracy: 0.5584 - val_f1_score: 0.5553 - lr: 8.1873e-04\n",
      "Epoch 6/10\n",
      "7200/7200 [==============================] - 2134s 296ms/step - loss: 0.8130 - categorical_accuracy: 0.6593 - f1_score: 0.6585 - val_loss: 1.0815 - val_categorical_accuracy: 0.5497 - val_f1_score: 0.5494 - lr: 7.4082e-04\n",
      "Epoch 7/10\n",
      "7200/7200 [==============================] - 2134s 296ms/step - loss: 0.7429 - categorical_accuracy: 0.6913 - f1_score: 0.6908 - val_loss: 1.1974 - val_categorical_accuracy: 0.5416 - val_f1_score: 0.5383 - lr: 6.7032e-04\n",
      "Epoch 8/10\n",
      "7200/7200 [==============================] - 2134s 296ms/step - loss: 0.6665 - categorical_accuracy: 0.7249 - f1_score: 0.7246 - val_loss: 1.3285 - val_categorical_accuracy: 0.5279 - val_f1_score: 0.5251 - lr: 6.0653e-04\n",
      "Epoch 9/10\n",
      "7200/7200 [==============================] - 2136s 297ms/step - loss: 0.5883 - categorical_accuracy: 0.7593 - f1_score: 0.7591 - val_loss: 1.5202 - val_categorical_accuracy: 0.5298 - val_f1_score: 0.5285 - lr: 5.4881e-04\n",
      "Epoch 10/10\n",
      "7200/7200 [==============================] - 2134s 296ms/step - loss: 0.5122 - categorical_accuracy: 0.7922 - f1_score: 0.7921 - val_loss: 1.7636 - val_categorical_accuracy: 0.5201 - val_f1_score: 0.5194 - lr: 4.9659e-04\n"
     ]
    }
   ],
   "source": [
    "#model_list = [cnn1,cnn2, cnn3,cnn4,cnn5,cnn6, cnn8, cnn9, cnn10]\n",
    "model_list = [transformer_classifier1]#\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 3:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "seeds = [42]\n",
    "for seed in seeds:\n",
    "    keras.utils.set_random_seed(seed)\n",
    "    for model_obj in model_list:\n",
    "        model = model_obj.Model(vocabulary2)\n",
    "        model.model.compile(optimizer=keras.optimizers.Adamax(learning_rate=0.001),\n",
    "                           loss=keras.losses.categorical_crossentropy,\n",
    "                           metrics=[keras.metrics.categorical_accuracy, tfa.metrics.F1Score(num_classes=6, average='weighted')]\n",
    "                           )\n",
    "        print(model.name)\n",
    "        print(model.model.summary())\n",
    "        if not os.path.exists(f\"logs/{model.name}\"):\n",
    "            os.mkdir(f\"logs/{model.name}\")\n",
    "        if not os.path.exists(f\"checkpoint/{model.name}\"):\n",
    "            os.mkdir(f\"checkpoint/{model.name}\")\n",
    "        chekpoint = keras.callbacks.ModelCheckpoint(f'checkpoint/{model.name}/', save_weights_only=True,\n",
    "        monitor='val_f1_score',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=f\"logs/{model.name}\")\n",
    "        model.run_experiment([train['review_text'], train['n_comments'], train['n_votes']], train['rating'], epochs=10, callbacks=[keras.callbacks.LearningRateScheduler(scheduler,0),chekpoint, tensorboard_callback], batch_size=100, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.load_weights('checkpoint/unet1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "res = model.model.predict([train['review_text'], train['n_comments'], train['n_votes']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "restest = model.model.predict([test['review_text'], test['n_comments'], test['n_votes']])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = []\n",
    "for line in tqdm(restest):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "test_data = np.array(ff)\n",
    "\n",
    "ff = []\n",
    "for line in tqdm(res):\n",
    "    tmp = -2\n",
    "    category = None\n",
    "    for i in (range(6)):\n",
    "        if line[i] > tmp:\n",
    "            category = i\n",
    "            tmp = line[i]\n",
    "    ff.append(category)\n",
    "train_data = np.array(ff)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(train['rating'], train_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test['rating'] = test_data\n",
    "\n",
    "id = test['review_id'].to_numpy()\n",
    "rating = test['rating'].to_numpy()\n",
    "df = pd.DataFrame( columns=['review_id', 'rating'])\n",
    "df['review_id'] = id\n",
    "df['rating'] = rating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('submission_unet2_embedding_class_weights_model.csv',index=False )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.model.save('unet2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
