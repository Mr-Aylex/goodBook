{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from nltk.tag import map_tag\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_non_alphanum, strip_multiple_whitespaces, strip_punctuation, strip_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../dataset/goodreads_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'prepro_stem' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m arch \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m../dataset/archive/prepro_train_archive_stem.npy\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\numpy\\lib\\npyio.py:413\u001B[0m, in \u001B[0;36mload\u001B[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001B[0m\n\u001B[0;32m    411\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mformat\u001B[39m\u001B[38;5;241m.\u001B[39mopen_memmap(file, mode\u001B[38;5;241m=\u001B[39mmmap_mode)\n\u001B[0;32m    412\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 413\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mallow_pickle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_pickle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    414\u001B[0m \u001B[43m                                 \u001B[49m\u001B[43mpickle_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpickle_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    415\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    416\u001B[0m     \u001B[38;5;66;03m# Try a pickle\u001B[39;00m\n\u001B[0;32m    417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m allow_pickle:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\numpy\\lib\\format.py:746\u001B[0m, in \u001B[0;36mread_array\u001B[1;34m(fp, allow_pickle, pickle_kwargs)\u001B[0m\n\u001B[0;32m    744\u001B[0m     pickle_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    745\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 746\u001B[0m     array \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(fp, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_kwargs)\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mUnicodeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;66;03m# Friendlier error message\u001B[39;00m\n\u001B[0;32m    749\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mUnicodeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnpickling a python object failed: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    750\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou may need to pass the encoding= option \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    751\u001B[0m                        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mto numpy.load\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (err,)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: Can't get attribute 'prepro_stem' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "arch = np.load(file=\"../dataset/archive/prepro_train_archive_stem.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_train = train['review_text']\n",
    "x_train_rm_st = x_train\n",
    "y_train = train['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_train_rm_st = pd.DataFrame(data=arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         This is a special book. It started slow for ab...\n",
       "1         Recommended by Don Katz. Avail for free in Dec...\n",
       "2         A fun, fast paced science fiction thriller. I ...\n",
       "3         Recommended reading to understand what is goin...\n",
       "4         I really enjoyed this book, and there is a lot...\n",
       "                                ...                        \n",
       "899995    3.5 stars. \\n Jenna is a popular YA author and...\n",
       "899996    This was a quick read for me. I have read a lo...\n",
       "899997    ** spoiler alert ** \\n 3.5 stars. \\n This book...\n",
       "899998    ** spoiler alert ** \\n Another fun read from M...\n",
       "899999    ** spoiler alert ** \\n 3.5 stars \\n I liked it...\n",
       "Name: review_text, Length: 900000, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>special book . started slow first third , midd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recommended . free : http : //www.audible.com/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fun , fast paced science fiction thriller . re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recommended reading understand going middle am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>really enjoyed book , lot recommend . drag lit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899995</th>\n",
       "      <td>3.5 . popular author agent want character firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899996</th>\n",
       "      <td>wa quick read . read lot book recently one ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899997</th>\n",
       "      <td>* spoiler alert * 3.5 . book sweet inside ! 's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899998</th>\n",
       "      <td>* spoiler alert another fun read ! 's new assi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899999</th>\n",
       "      <td>* spoiler alert * 3.5 liked ! story original '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       special book . started slow first third , midd...\n",
       "1       recommended . free : http : //www.audible.com/...\n",
       "2       fun , fast paced science fiction thriller . re...\n",
       "3       recommended reading understand going middle am...\n",
       "4       really enjoyed book , lot recommend . drag lit...\n",
       "...                                                   ...\n",
       "899995  3.5 . popular author agent want character firs...\n",
       "899996  wa quick read . read lot book recently one ver...\n",
       "899997  * spoiler alert * 3.5 . book sweet inside ! 's...\n",
       "899998  * spoiler alert another fun read ! 's new assi...\n",
       "899999  * spoiler alert * 3.5 liked ! story original '...\n",
       "\n",
       "[900000 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rm_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#x_train_rm_st = x_train_rm_st.apply(lambda x: strip_numeric(strip_non_alphanum(strip_multiple_whitespaces(remove_stopwords(strip_punctuation(x))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#this function count all words in dataset\n",
    "def count_dataset(dataset) -> dict:\n",
    "    test = dataset.apply(lambda x: Counter(x.split()))\n",
    "    list_of_word = {}\n",
    "    for el in tqdm(test):\n",
    "        for word, nb in el.items():\n",
    "            if not list_of_word.get(word) is None:\n",
    "                list_of_word[word].append(nb)\n",
    "            else:\n",
    "                list_of_word[word] = [nb]\n",
    "    return list_of_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 900000/900000 [00:21<00:00, 42711.84it/s]\n"
     ]
    }
   ],
   "source": [
    "words = count_dataset(x_train_rm_st[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525880\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# res2 = 0\n",
    "# for x in range(len(x_train)):\n",
    "#\n",
    "#     res2 += len(x_train.iloc[x])\n",
    "# res2\n",
    "#\n",
    "# res = 0\n",
    "# for x in range(len(x_train_rm_st)):\n",
    "#\n",
    "#     res += len(x_train_rm_st.iloc[x])\n",
    "# res\n",
    "#494871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens= 550000,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1400,\n",
    "    vocabulary=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing data\n"
     ]
    }
   ],
   "source": [
    "print(\"tokenizing data\")\n",
    "#layer = tf.keras.layers.StringLookup()\n",
    "vectorize_layer.adapt(x_train_rm_st[0], batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# print(len(x_train_rm_st.iloc[0]))\n",
    "# print(len(x_train.iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463288"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorize_layer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.save('voc_lemm_without_NP_NEG', np.array(vectorize_layer.get_vocabulary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = [w for w in voc if len(w) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463250"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = [w for w in voc if not w.isnumeric()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453117"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../vocabulaire/voc_lemm_without_NP_NEG.npy', np.array(voc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
