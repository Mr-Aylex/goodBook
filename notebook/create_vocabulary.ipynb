{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.tag import map_tag\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_non_alphanum, strip_multiple_whitespaces, strip_punctuation, strip_numeric"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../dataset/goodreads_train.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "arch = np.load(file=\"../prepro_train_archive.npy\", allow_pickle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "x_train = train['review_text']\n",
    "x_train_rm_st = x_train\n",
    "y_train = train['rating']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "x_train_rm_st = pd.DataFrame(data=arch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "0         This is a special book. It started slow for ab...\n1         Recommended by Don Katz. Avail for free in Dec...\n2         A fun, fast paced science fiction thriller. I ...\n3         Recommended reading to understand what is goin...\n4         I really enjoyed this book, and there is a lot...\n                                ...                        \n899995    3.5 stars. \\n Jenna is a popular YA author and...\n899996    This was a quick read for me. I have read a lo...\n899997    ** spoiler alert ** \\n 3.5 stars. \\n This book...\n899998    ** spoiler alert ** \\n Another fun read from M...\n899999    ** spoiler alert ** \\n 3.5 stars \\n I liked it...\nName: review_text, Length: 900000, dtype: object"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                        0\n0       special book . start slow first third , middl ...\n1       recommend katz . avail free decemb : http : //...\n2       fun , fast pace scienc fiction thriller . read...\n3       recommend read understand go middl america , p...\n4       realli enjoy book , lot recommend . drag littl...\n...                                                   ...\n899995  3.5 star . jenna popular ya author agent want ...\n899996  quick read . read lot new adult book recent on...\n899997  * * spoiler alert * * 3.5 star . book sweet in...\n899998  * * spoiler alert * * anoth fun read ms evanov...\n899999  * * spoiler alert * * 3.5 star like ! stori or...\n\n[900000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>special book . start slow first third , middl ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>recommend katz . avail free decemb : http : //...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>fun , fast pace scienc fiction thriller . read...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>recommend read understand go middl america , p...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>realli enjoy book , lot recommend . drag littl...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>899995</th>\n      <td>3.5 star . jenna popular ya author agent want ...</td>\n    </tr>\n    <tr>\n      <th>899996</th>\n      <td>quick read . read lot new adult book recent on...</td>\n    </tr>\n    <tr>\n      <th>899997</th>\n      <td>* * spoiler alert * * 3.5 star . book sweet in...</td>\n    </tr>\n    <tr>\n      <th>899998</th>\n      <td>* * spoiler alert * * anoth fun read ms evanov...</td>\n    </tr>\n    <tr>\n      <th>899999</th>\n      <td>* * spoiler alert * * 3.5 star like ! stori or...</td>\n    </tr>\n  </tbody>\n</table>\n<p>900000 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rm_st"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning data\n",
      "remove stopword\n",
      "non alphanumeric\n",
      "multiple whitespaces\n",
      "strip punctuation\n",
      "<bound method NDFrame.head of                                                         0\n",
      "0       special book . start slow first third , middl ...\n",
      "1       recommend katz . avail free decemb : http : //...\n",
      "2       fun , fast pace scienc fiction thriller . read...\n",
      "3       recommend read understand go middl america , p...\n",
      "4       realli enjoy book , lot recommend . drag littl...\n",
      "...                                                   ...\n",
      "899995  3.5 star . jenna popular ya author agent want ...\n",
      "899996  quick read . read lot new adult book recent on...\n",
      "899997  * * spoiler alert * * 3.5 star . book sweet in...\n",
      "899998  * * spoiler alert * * anoth fun read ms evanov...\n",
      "899999  * * spoiler alert * * 3.5 star like ! stori or...\n",
      "\n",
      "[900000 rows x 1 columns]>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, Series found",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [43]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrip punctuation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(x_train_rm_st\u001B[38;5;241m.\u001B[39mhead)\n\u001B[1;32m----> 7\u001B[0m x_train_rm_st \u001B[38;5;241m=\u001B[39m \u001B[43mx_train_rm_st\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstrip_numeric\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrip_non_alphanum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrip_multiple_whitespaces\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremove_stopwords\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstrip_punctuation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Book_Review_Project\\lib\\site-packages\\pandas\\core\\frame.py:9555\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[0;32m   9544\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m   9546\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m   9547\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   9548\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   9553\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m   9554\u001B[0m )\n\u001B[1;32m-> 9555\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Book_Review_Project\\lib\\site-packages\\pandas\\core\\apply.py:746\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    743\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    744\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[1;32m--> 746\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Book_Review_Project\\lib\\site-packages\\pandas\\core\\apply.py:873\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    872\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 873\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    875\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[0;32m    876\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Book_Review_Project\\lib\\site-packages\\pandas\\core\\apply.py:889\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    886\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    887\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m    888\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m--> 889\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    890\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m    891\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m    892\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m    893\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Input \u001B[1;32mIn [43]\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrip punctuation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(x_train_rm_st\u001B[38;5;241m.\u001B[39mhead)\n\u001B[1;32m----> 7\u001B[0m x_train_rm_st \u001B[38;5;241m=\u001B[39m x_train_rm_st\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: strip_numeric(strip_non_alphanum(strip_multiple_whitespaces(remove_stopwords(\u001B[43mstrip_punctuation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)))))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Book_Review_Project\\lib\\site-packages\\gensim\\parsing\\preprocessing.py:142\u001B[0m, in \u001B[0;36mstrip_punctuation\u001B[1;34m(s)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstrip_punctuation\u001B[39m(s):\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;124;03m\"\"\"Replace ASCII punctuation characters with spaces in `s` using :const:`~gensim.parsing.preprocessing.RE_PUNCT`.\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \n\u001B[0;32m    124\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    140\u001B[0m \n\u001B[0;32m    141\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 142\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_unicode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    143\u001B[0m     \u001B[38;5;66;03m# For unicode enhancement options see https://github.com/RaRe-Technologies/gensim/issues/2962\u001B[39;00m\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m RE_PUNCT\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m, s)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Book_Review_Project\\lib\\site-packages\\gensim\\utils.py:365\u001B[0m, in \u001B[0;36many2unicode\u001B[1;34m(text, encoding, errors)\u001B[0m\n\u001B[0;32m    363\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(text, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    364\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m text\n\u001B[1;32m--> 365\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: decoding to str: need a bytes-like object, Series found"
     ]
    }
   ],
   "source": [
    "print(\"cleaning data\")\n",
    "print(\"remove stopword\")\n",
    "print(\"non alphanumeric\")\n",
    "print(\"multiple whitespaces\")\n",
    "print(\"strip punctuation\")\n",
    "print(x_train_rm_st.head)\n",
    "x_train_rm_st = x_train_rm_st.apply(lambda x: strip_numeric(strip_non_alphanum(strip_multiple_whitespaces(remove_stopwords(strip_punctuation(x))))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "#this function count all words in dataset\n",
    "def count_dataset(dataset) -> dict:\n",
    "    test = dataset.apply(lambda x: Counter(x.split()))\n",
    "    list_of_word = {}\n",
    "    for el in test:\n",
    "        for word, nb in el.items():\n",
    "            if not list_of_word.get(word) is None:\n",
    "                list_of_word[word].append(nb)\n",
    "            else:\n",
    "                list_of_word[word] = [nb]\n",
    "    return list_of_word"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "words = count_dataset(x_train_rm_st[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494871\n"
     ]
    }
   ],
   "source": [
    "print(len(words))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# res2 = 0\n",
    "# for x in range(len(x_train)):\n",
    "#\n",
    "#     res2 += len(x_train.iloc[x])\n",
    "# res2\n",
    "#\n",
    "# res = 0\n",
    "# for x in range(len(x_train_rm_st)):\n",
    "#\n",
    "#     res += len(x_train_rm_st.iloc[x])\n",
    "# res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens= 494871,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1400,\n",
    "    vocabulary=None)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizing data\n"
     ]
    }
   ],
   "source": [
    "print(\"tokenizing data\")\n",
    "#layer = tf.keras.layers.StringLookup()\n",
    "vectorize_layer.adapt(x_train_rm_st, batch_size=10000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267\n",
      "2119\n"
     ]
    }
   ],
   "source": [
    "# print(len(x_train_rm_st.iloc[0]))\n",
    "# print(len(x_train.iloc[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "np.save('voc2', np.array(vectorize_layer.get_vocabulary()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
