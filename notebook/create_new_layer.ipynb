{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class TextPrepro(keras.layers.Layer):\n",
    "    def __init__(self, input_dim):\n",
    "        super(TextPrepro, self).__init__()\n",
    "        self.total = tf.Variable(initial_value=tf.zeros((input_dim,)), trainable=False)\n",
    "\n",
    "        self.dic = {}\n",
    "        all_stop_word = stopwords.words(\"english\")\n",
    "        for stop_word in all_stop_word:\n",
    "            self.dic[stop_word] = stop_word\n",
    "\n",
    "    def prepro(text):\n",
    "        words = text.lower()\n",
    "        tokens = nltk.word_tokenize(words)\n",
    "        words_stop_less = [w for w in tokens if dic.get(w) == None]\n",
    "        stemmed = [PorterStemmer().stem(w) for w in words_stop_less]\n",
    "        return \" \".join(stemmed)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.prepro(inputs)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [10], line 7\u001B[0m\n\u001B[0;32m      1\u001B[0m vectorize_layer \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mTextVectorization(\n\u001B[0;32m      2\u001B[0m     max_tokens\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m376576\u001B[39m,\n\u001B[0;32m      3\u001B[0m     standardize\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlower_and_strip_punctuation\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      4\u001B[0m     split\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwhitespace\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      5\u001B[0m     output_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mint\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m      6\u001B[0m     output_sequence_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1400\u001B[39m,\n\u001B[1;32m----> 7\u001B[0m     vocabulary\u001B[38;5;241m=\u001B[39m\u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvoc.npy\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens= 376576,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    output_mode='int',\n",
    "    output_sequence_length=1400,\n",
    "    vocabulary=np.load('voc.npy'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [1,1] [Op:Fill]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [12], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39madd(tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mInput(shape\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m1\u001B[39m,), dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mstring))\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39madd(\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mTextPrepro\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      6\u001B[0m model\u001B[38;5;241m.\u001B[39madd(vectorize_layer)\n\u001B[0;32m      7\u001B[0m model\u001B[38;5;241m.\u001B[39madd(tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlayers\u001B[38;5;241m.\u001B[39mDense(\u001B[38;5;241m1\u001B[39m, activation\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mactivations\u001B[38;5;241m.\u001B[39mlinear))\n",
      "Cell \u001B[1;32mIn [9], line 4\u001B[0m, in \u001B[0;36mTextPrepro.__init__\u001B[1;34m(self, input_dim)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_dim):\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28msuper\u001B[39m(TextPrepro, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtotal \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mVariable(initial_value\u001B[38;5;241m=\u001B[39m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m, trainable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdic \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m      7\u001B[0m     all_stop_word \u001B[38;5;241m=\u001B[39m stopwords\u001B[38;5;241m.\u001B[39mwords(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\goodBook\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001B[0m, in \u001B[0;36mraise_from_not_ok_status\u001B[1;34m(e, name)\u001B[0m\n\u001B[0;32m   7207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mraise_from_not_ok_status\u001B[39m(e, name):\n\u001B[0;32m   7208\u001B[0m   e\u001B[38;5;241m.\u001B[39mmessage \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m name: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 7209\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: {{function_node __wrapped__Fill_device_/job:localhost/replica:0/task:0/device:GPU:0}} dims must represent a vector, got shape [1,1] [Op:Fill]"
     ]
    }
   ],
   "source": [
    "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
    "\n",
    "model.add(\n",
    "    TextPrepro((1,))\n",
    ")\n",
    "model.add(vectorize_layer)\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.keras.activations.linear))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.mse\n",
    "              )"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
